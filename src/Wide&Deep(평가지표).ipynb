{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide & Deep Learning model 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>action_type</th>\n",
       "      <th>hit_pss_tm</th>\n",
       "      <th>sech_kwd</th>\n",
       "      <th>tot_pag_view_ct</th>\n",
       "      <th>tot_sess_hr_v</th>\n",
       "      <th>trfc_src</th>\n",
       "      <th>dvc_ctg_nm</th>\n",
       "      <th>de_dt</th>\n",
       "      <th>buy_am</th>\n",
       "      <th>buy_ct</th>\n",
       "      <th>clnt_gender</th>\n",
       "      <th>clnt_age</th>\n",
       "      <th>clac_nm3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49906</td>\n",
       "      <td>6</td>\n",
       "      <td>627381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>20190701</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>30.0</td>\n",
       "      <td>기능성 우유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67265</td>\n",
       "      <td>6</td>\n",
       "      <td>313631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>mobile_app</td>\n",
       "      <td>20190701</td>\n",
       "      <td>56900</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>40.0</td>\n",
       "      <td>성인용 침구 세트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68972</td>\n",
       "      <td>6</td>\n",
       "      <td>554066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>20190701</td>\n",
       "      <td>9980</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>50.0</td>\n",
       "      <td>인스턴트 라이스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41763</td>\n",
       "      <td>6</td>\n",
       "      <td>1241857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>20190701</td>\n",
       "      <td>1290</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>40.0</td>\n",
       "      <td>새송이버섯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15344</td>\n",
       "      <td>6</td>\n",
       "      <td>120487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>unknown</td>\n",
       "      <td>20190701</td>\n",
       "      <td>4100</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cokes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clnt_id  action_type  hit_pss_tm  sech_kwd  tot_pag_view_ct  tot_sess_hr_v  \\\n",
       "0    49906            6      627381       NaN             63.0         2211.0   \n",
       "1    67265            6      313631       NaN             10.0          313.0   \n",
       "2    68972            6      554066       NaN             31.0          652.0   \n",
       "3    41763            6     1241857       NaN             39.0         1242.0   \n",
       "4    15344            6      120487       NaN             10.0          133.0   \n",
       "\n",
       "  trfc_src  dvc_ctg_nm     de_dt  buy_am  buy_ct clnt_gender  clnt_age  \\\n",
       "0   DIRECT     unknown  20190701    1990       1           F      30.0   \n",
       "1  unknown  mobile_app  20190701   56900       1           F      40.0   \n",
       "2   DIRECT     unknown  20190701    9980       2           F      50.0   \n",
       "3   DIRECT     unknown  20190701    1290       1           F      40.0   \n",
       "4   DIRECT     unknown  20190701    4100       1           F      40.0   \n",
       "\n",
       "    clac_nm3  \n",
       "0     기능성 우유  \n",
       "1  성인용 침구 세트  \n",
       "2   인스턴트 라이스  \n",
       "3      새송이버섯  \n",
       "4      Cokes  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=os.getenv(\"HOME\") + ('/repo/Lpoint-Hackathon/src/new_data/all_data_nm3.csv')\n",
    "Input = pd.read_csv(path)\n",
    "data = Input.copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\n",
    "    \"clnt_id\", \"clnt_age\", \"hit_pss_tm\", \"action_type\", \"de_dt\", \n",
    "    \"hit_pss_tm\", \"trans_id\", \"tot_pag_view_ct\", \"tot_sess_hr_v\", \n",
    "    \"trfc_src\", \"dvc_ctg_nm\"\n",
    "]\n",
    "\n",
    "CATEGORICAL_COLUMNS = [\n",
    "    \"clnt_gender\", \"trfc_src\", \"dvc_ctg_nm\"\n",
    "]\n",
    "\n",
    "CONTINUOUS_COLUMNS = [\n",
    "    \"clnt_id\", \"clnt_age\", \"hit_pss_tm\", \"action_type\", \"de_dt\", \n",
    "    \"tot_pag_view_ct\", \"tot_sess_hr_v\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in CATEGORICAL_COLUMNS:\n",
    "    le = LabelEncoder()\n",
    "    data[c] = le.fit_transform(data[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>action_type</th>\n",
       "      <th>hit_pss_tm</th>\n",
       "      <th>sech_kwd</th>\n",
       "      <th>tot_pag_view_ct</th>\n",
       "      <th>tot_sess_hr_v</th>\n",
       "      <th>trfc_src</th>\n",
       "      <th>dvc_ctg_nm</th>\n",
       "      <th>de_dt</th>\n",
       "      <th>buy_am</th>\n",
       "      <th>buy_ct</th>\n",
       "      <th>clnt_gender</th>\n",
       "      <th>clnt_age</th>\n",
       "      <th>clac_nm3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49906</td>\n",
       "      <td>6</td>\n",
       "      <td>627381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190701</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>기능성 우유</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67265</td>\n",
       "      <td>6</td>\n",
       "      <td>313631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20190701</td>\n",
       "      <td>56900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>성인용 침구 세트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68972</td>\n",
       "      <td>6</td>\n",
       "      <td>554066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190701</td>\n",
       "      <td>9980</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>인스턴트 라이스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41763</td>\n",
       "      <td>6</td>\n",
       "      <td>1241857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190701</td>\n",
       "      <td>1290</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>새송이버섯</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15344</td>\n",
       "      <td>6</td>\n",
       "      <td>120487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190701</td>\n",
       "      <td>4100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cokes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clnt_id  action_type  hit_pss_tm  sech_kwd  tot_pag_view_ct  tot_sess_hr_v  \\\n",
       "0    49906            6      627381       NaN             63.0         2211.0   \n",
       "1    67265            6      313631       NaN             10.0          313.0   \n",
       "2    68972            6      554066       NaN             31.0          652.0   \n",
       "3    41763            6     1241857       NaN             39.0         1242.0   \n",
       "4    15344            6      120487       NaN             10.0          133.0   \n",
       "\n",
       "   trfc_src  dvc_ctg_nm     de_dt  buy_am  buy_ct  clnt_gender  clnt_age  \\\n",
       "0         0           3  20190701    1990       1            0      30.0   \n",
       "1         6           1  20190701   56900       1            0      40.0   \n",
       "2         0           3  20190701    9980       2            0      50.0   \n",
       "3         0           3  20190701    1290       1            0      40.0   \n",
       "4         0           3  20190701    4100       1            0      40.0   \n",
       "\n",
       "    clac_nm3  \n",
       "0     기능성 우유  \n",
       "1  성인용 침구 세트  \n",
       "2   인스턴트 라이스  \n",
       "3      새송이버섯  \n",
       "4      Cokes  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 데이터, Test 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clac_nm3'] = data['clac_nm3'].astype(str)\n",
    "le = LabelEncoder()\n",
    "data['clac_nm3'] = le.fit_transform(data['clac_nm3'])\n",
    "Label = data['clac_nm3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>action_type</th>\n",
       "      <th>hit_pss_tm</th>\n",
       "      <th>sech_kwd</th>\n",
       "      <th>tot_pag_view_ct</th>\n",
       "      <th>tot_sess_hr_v</th>\n",
       "      <th>trfc_src</th>\n",
       "      <th>dvc_ctg_nm</th>\n",
       "      <th>de_dt</th>\n",
       "      <th>buy_am</th>\n",
       "      <th>buy_ct</th>\n",
       "      <th>clnt_gender</th>\n",
       "      <th>clnt_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49906</td>\n",
       "      <td>6</td>\n",
       "      <td>627381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190701</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67265</td>\n",
       "      <td>6</td>\n",
       "      <td>313631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>20190701</td>\n",
       "      <td>56900</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68972</td>\n",
       "      <td>6</td>\n",
       "      <td>554066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190701</td>\n",
       "      <td>9980</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41763</td>\n",
       "      <td>6</td>\n",
       "      <td>1241857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1242.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190701</td>\n",
       "      <td>1290</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15344</td>\n",
       "      <td>6</td>\n",
       "      <td>120487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190701</td>\n",
       "      <td>4100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123090</th>\n",
       "      <td>64811</td>\n",
       "      <td>6</td>\n",
       "      <td>1158981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20190930</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123091</th>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "      <td>803090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>806.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190930</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123092</th>\n",
       "      <td>72078</td>\n",
       "      <td>6</td>\n",
       "      <td>951307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190930</td>\n",
       "      <td>3980</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123093</th>\n",
       "      <td>39156</td>\n",
       "      <td>6</td>\n",
       "      <td>2592159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2624.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190930</td>\n",
       "      <td>990</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123094</th>\n",
       "      <td>57042</td>\n",
       "      <td>6</td>\n",
       "      <td>4337678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>4345.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20190930</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123095 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        clnt_id  action_type  hit_pss_tm  sech_kwd  tot_pag_view_ct  \\\n",
       "0         49906            6      627381       NaN             63.0   \n",
       "1         67265            6      313631       NaN             10.0   \n",
       "2         68972            6      554066       NaN             31.0   \n",
       "3         41763            6     1241857       NaN             39.0   \n",
       "4         15344            6      120487       NaN             10.0   \n",
       "...         ...          ...         ...       ...              ...   \n",
       "123090    64811            6     1158981       NaN             34.0   \n",
       "123091       49            6      803090       NaN             24.0   \n",
       "123092    72078            6      951307       NaN             54.0   \n",
       "123093    39156            6     2592159       NaN             68.0   \n",
       "123094    57042            6     4337678       NaN             86.0   \n",
       "\n",
       "        tot_sess_hr_v  trfc_src  dvc_ctg_nm     de_dt  buy_am  buy_ct  \\\n",
       "0              2211.0         0           3  20190701    1990       1   \n",
       "1               313.0         6           1  20190701   56900       1   \n",
       "2               652.0         0           3  20190701    9980       2   \n",
       "3              1242.0         0           3  20190701    1290       1   \n",
       "4               133.0         0           3  20190701    4100       1   \n",
       "...               ...       ...         ...       ...     ...     ...   \n",
       "123090         1159.0         0           0  20190930    1000       1   \n",
       "123091          806.0         0           3  20190930    2000       1   \n",
       "123092         1200.0         0           3  20190930    3980       1   \n",
       "123093         2624.0         0           3  20190930     990       1   \n",
       "123094         4345.0         0           3  20190930    1090       1   \n",
       "\n",
       "        clnt_gender  clnt_age  \n",
       "0                 0      30.0  \n",
       "1                 0      40.0  \n",
       "2                 0      50.0  \n",
       "3                 0      40.0  \n",
       "4                 0      40.0  \n",
       "...             ...       ...  \n",
       "123090            0      50.0  \n",
       "123091            0      50.0  \n",
       "123092            0      40.0  \n",
       "123093            1      40.0  \n",
       "123094            0      30.0  \n",
       "\n",
       "[123095 rows x 13 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_len = len(data['clac_nm3'].value_counts())\n",
    "lable_key = data['clac_nm3'].value_counts().keys()\n",
    "data.drop(['clac_nm3'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = Label.copy()\n",
    "label = np.eye(lab_len)[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([254, 275, 688, 337, 739, 267, 410, 221, 509,  95,\n",
       "            ...\n",
       "            268, 426, 682, 971, 907, 779, 746, 651, 459,  31],\n",
       "           dtype='int64', length=1055)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lable_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x , train_y , test_y = train_test_split(data , label , test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터:  (98476, 14)\n",
      "Test 데이터:  (24619, 14)\n",
      "Train 라벨:  (98476, 1055)\n",
      "Test 라벨:  (24619, 1055)\n"
     ]
    }
   ],
   "source": [
    "print('Train 데이터: ', train_x.shape)\n",
    "print('Test 데이터: ', test_x.shape)\n",
    "print('Train 라벨: ', train_y.shape)\n",
    "print('Test 라벨: ', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x , train_y , val_y = train_test_split(train_x , train_y , test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터:  (88628, 14)\n",
      "Val 데이터:  (9848, 14)\n",
      "Train 라벨:  (88628, 1055)\n",
      "Val 라벨:  (9848, 1055)\n"
     ]
    }
   ],
   "source": [
    "print('Train 데이터: ', train_x.shape)\n",
    "print('Val 데이터: ', val_x.shape)\n",
    "print('Train 라벨: ', train_y.shape)\n",
    "print('Val 라벨: ', val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def df_to_dataset(dataframe, label, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = label.copy()\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels.values))\n",
    "    if shuffle:\n",
    "        ds = ds.repeat()\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    gc.collect()\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # A small batch sized is used for demonstration purposes\n",
    "train_ds = df_to_dataset(train_x, train_y)\n",
    "val_ds = df_to_dataset(val_x, val_y)\n",
    "test_ds = df_to_dataset(test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 카테고리 값들과 연속값들을 뽑아냄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_category = np.array(train_x[CATEGORICAL_COLUMNS])\n",
    "test_x_category = np.array(test_x[CATEGORICAL_COLUMNS])\n",
    "val_x_category = np.array(val_x[CATEGORICAL_COLUMNS])\n",
    "\n",
    "train_x_continue = np.array(train_x[CONTINUOUS_COLUMNS], dtype='float64')\n",
    "test_x_continue = np.array(test_x[CONTINUOUS_COLUMNS], dtype='float64')\n",
    "val_x_continue = np.array(val_x[CONTINUOUS_COLUMNS], dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_x_continue = scaler.fit_transform(train_x_continue)\n",
    "test_x_continue = scaler.transform(test_x_continue)\n",
    "val_x_continue = scaler.transform(val_x_continue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 정규화 내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6401872159228421\n",
      "-2.7128231458173024\n",
      "-0.35443517464351554\n",
      "-1.7566430544076208\n",
      "-5.57768293430038\n"
     ]
    }
   ],
   "source": [
    "print(train_x_continue[0].sum())\n",
    "print(train_x_continue[1].sum())\n",
    "print(train_x_continue[2].sum())\n",
    "print(train_x_continue[3].sum())\n",
    "print(train_x_continue[4].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - 정규화 한다고 다 더해서 1이 되거나 하지는 않는듯\n",
    " - 그렇다고 개별 값이 0~1은 아님"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial 하게 바꿔줌 \n",
    "### (비선형적인 설정으로 선형 회귀를 확장하는 방법. 즉 다항식 함수로 바꿔줌)\n",
    "    - 카테고리 값을 Polynomial로 바꿔줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sklearn.preprocessing.PolynomialFeatures 메소드\n",
    "    - degree : 다항식 차수\n",
    "    - interaction_only\n",
    "        - default는 False\n",
    "        - ex) degree = 3일 때, interaction_only=false 이면\n",
    "            - a^2, a^3, b^2, b^3, ab, a^2*b, ab^2 Feature가 추가되고,\n",
    "        - interaction_only=True 이면\n",
    "            - ab만 추가됨\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_category_poly = poly.fit_transform(train_x_continue)\n",
    "test_x_category_poly = poly.fit_transform(test_x_continue)\n",
    "val_x_category_poly = poly.fit_transform(val_x_continue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> feature가 8개 이므로, interaction은 7+6+5+4+3+2+1=28개 이고,\n",
    "상수항 1을 추가하여 8+28+1=37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * np.unique : np.arr 내 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.keras.layers.advanced_activations import ReLU, PReLU, LeakyReLU, ELU\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.keras.models import Model\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_model():\n",
    "    \n",
    "    category_inputs = []\n",
    "    category_embeds = []\n",
    "    \n",
    "    # Categorical Data Embedding\n",
    "    for i in range(len(CATEGORICAL_COLUMNS)):\n",
    "        \n",
    "        # input - embedding - flatten 순으로 layer 쌓기\n",
    "        input_i = Input(shape=(1,), dtype='int32')\n",
    "        \n",
    "        dim = len(np.unique(data[CATEGORICAL_COLUMNS[i]]))\n",
    "        # dim : data에서 카테고리별 요소가 몇 종류인지?\n",
    "        # 예시 data[학력] = '초', '중', '고' => dim = 3\n",
    "        \n",
    "        embed_dim = int(np.ceil(dim ** 0.5))\n",
    "        # embedding 차원을 0.5배 정도로 수행? (연산은 루트 올림인디?)\n",
    "        # 왜 임베딩 차원을 이렇게 하는지 추후 검토\n",
    "        \n",
    "        embed_i = Embedding(dim, embed_dim, input_length=1)(input_i)\n",
    "        # dim : 데이터가 몇 종류 있는지 = 임베딩 벡터를 몇 개 뽑아낼 것인지\n",
    "        # embed_dim : 임베딩 처리 후 벡터의 차원 = 임베딩 벡터를 몇 차원 벡터로 뽑아 낼 것인지\n",
    "        # input_length : 입력 데이터 길이\n",
    "        \n",
    "        flatten_i = Flatten()(embed_i)\n",
    "        # category 값을 임베딩환 벡터들을 flatten\n",
    "        # 서로 다른 값의 벡터 요소가 합쳐져도 괜찮은지??\n",
    "        # 어차피 class에 대한 순서가 있으니 상관 없을듯\n",
    "        \n",
    "        category_inputs.append(input_i)\n",
    "        category_embeds.append(flatten_i)\n",
    "        \n",
    "    # continuous 데이터 input\n",
    "    continue_input = Input(shape=(len(CONTINUOUS_COLUMNS),))\n",
    "    continue_dense = Dense(256, use_bias=False)(continue_input)\n",
    "    # use_bias = False로 하는 이유는??\n",
    "    \n",
    "    # category와 continue를 합침\n",
    "    concat_embeds = concatenate([continue_dense] + category_embeds)\n",
    "    concat_embeds = Activation('relu')(concat_embeds)\n",
    "    # Activation 효과 다시 공부\n",
    "    # relu 말고 다른 것은 어떤지??\n",
    "    bn_concat = BatchNormalization()(concat_embeds)\n",
    "    # Batch Normalization 효과 다시 공부\n",
    "    \n",
    "    fc1 = Dense(512, use_bias=False)(bn_concat)\n",
    "    relu1 = ReLU()(fc1)\n",
    "    bn1 = BatchNormalization()(relu1)\n",
    "    fc2 = Dense(256, use_bias=False)(bn1)\n",
    "    relu2 = ReLU()(fc2)\n",
    "    bn2 = BatchNormalization()(relu2)\n",
    "    fc3 = Dense(128)(bn2)\n",
    "    relu3 = ReLU()(fc3)\n",
    "    \n",
    "    return category_inputs, continue_input, relu3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wide_model(poly):\n",
    "    dim = poly.shape[1]\n",
    "    return tf.keras.layers.Input(shape=(dim,))\n",
    "\n",
    "# x_train_category_poly : 카테고리 데이터를 숫자로 바꾸고, Poly Feature를 추가한 것\n",
    "# Poly Feature : a, b, c Feature를 이용해서 ab, bc, ca Feature를 만든것\n",
    "# 데이터의 shape 만 가져옴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * input - embedding - flatten 순으로 layer 쌓기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_inputs, continue_input, deep_model = get_deep_model()\n",
    "wide_model = get_wide_model(train_x_category_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_5:0' shape=(None, 29) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 're_lu_2/Relu:0' shape=(None, 128) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide모델과 Deep model을 합치기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* wide model, deep model 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(None, 157) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_layer = concatenate([deep_model, wide_model])\n",
    "out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 입력 값들 shape 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_4:0' shape=(None, 7) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continue_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_1:0' shape=(None, 1) dtype=int32>,\n",
       " <tf.Tensor 'input_2:0' shape=(None, 1) dtype=int32>,\n",
       " <tf.Tensor 'input_3:0' shape=(None, 1) dtype=int32>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_5:0' shape=(None, 29) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wide_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 입력 값들 종합하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'input_4:0' shape=(None, 7) dtype=float32>,\n",
       " <tf.Tensor 'input_1:0' shape=(None, 1) dtype=int32>,\n",
       " <tf.Tensor 'input_2:0' shape=(None, 1) dtype=int32>,\n",
       " <tf.Tensor 'input_3:0' shape=(None, 1) dtype=int32>,\n",
       " <tf.Tensor 'input_5:0' shape=(None, 29) dtype=float32>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [continue_input] + category_inputs + [wide_model]\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* wide model, deep model 합친 것을 한 점으로 모으기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Dense(len(data['clac_nm3'].value_counts()), activation='sigmoid')(out_layer)\n",
    "# 여기서는 왜 relu가 아니고 sigmoid를 썻는지???\n",
    "# 마지막 출력 값 범위를 0~1로 출력하기 위함 일듯?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 7)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 2)         4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 3)         21          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 2)         8           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2)            0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3)            0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 263)          0           dense[0][0]                      \n",
      "                                                                 flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 263)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 263)          1052        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          134656      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131072      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 29)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 157)          0           re_lu_2[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1055)         166690      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 471,263\n",
      "Trainable params: 469,201\n",
      "Non-trainable params: 2,062\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='./data/wide-deep.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력 데이터\n",
    "\n",
    "    * 위에서 정의한 리스트 변수 inputs에 맞추어\n",
    "    * continue 데이터 => category 데이터 => poly data 순으로 입력 값을 넣어준다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * 데이터 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* x_train_continue\n",
    "    - 숫자형 데이터(나이, 학력 수치, gain, loss, 업무시간)를 float형으로 변환하고\n",
    "    - StandardScaler()를 통해 정규화 한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59579673, -1.0332683 , -0.69691289, ..., -1.21881681,\n",
       "         0.53646717,  0.33240989],\n",
       "       [ 1.4622614 ,  0.18845219, -0.93592448, ..., -1.21881681,\n",
       "        -1.05550571, -0.99742673],\n",
       "       [ 1.54746534,  1.41017268, -0.75276352, ..., -1.21881681,\n",
       "        -0.424724  , -0.75990586],\n",
       "       ...,\n",
       "       [-0.66519163,  0.18845219, -0.55282109, ...,  2.34855346,\n",
       "        -0.12435176, -0.64429836],\n",
       "       [ 0.80898128, -1.0332683 , -0.75433357, ...,  2.34855346,\n",
       "        -0.57491012, -0.73117915],\n",
       "       [ 1.27782757, -2.25498879, -0.10684869, ...,  2.34855346,\n",
       "         0.05587158, -0.23441721]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88628, 7)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_continue.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* x_train_category\n",
    "    - 범주형 데이터(업종, 학력, 결혼 여부, 직업, 가족관계, 인종, 성별, 국적)을  \n",
    "    - LabelEncoder()를 통해 숫자(정수)로 변경(인코딩)\n",
    "\n",
    "* x_train_category_poly\n",
    "    - 각 feature를 2개씩 쌍을 지어 내적한 결과로 Feature를 추가한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 3],\n",
       "       [0, 6, 1],\n",
       "       [0, 0, 3],\n",
       "       ...,\n",
       "       [0, 0, 3],\n",
       "       [0, 0, 3],\n",
       "       [0, 0, 3]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88628, 3)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_category.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, ..., 0, 0, 0]),\n",
       " array([0, 6, 0, ..., 0, 0, 0]),\n",
       " array([3, 1, 3, ..., 3, 3, 3])]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train_x_category[:, i] for i in range(train_x_category.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0, 0, 3],\n",
       "        [0, 6, 1],\n",
       "        [0, 0, 3],\n",
       "        ...,\n",
       "        [0, 0, 3],\n",
       "        [0, 0, 3],\n",
       "        [0, 0, 3]])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[train_x_category]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88628, 29)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_category_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * 모델 입력 데이터 설정 부분\n",
    " * category랑 category_poly랑 중복 아닌지??? => 나중에 확인할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = [train_x_continue] + [train_x_category[:, i] for i in range(train_x_category.shape[1])] + [train_x_category_poly]\n",
    "len(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.59579673, -1.0332683 , -0.69691289, ..., -1.21881681,\n",
       "         0.53646717,  0.33240989],\n",
       "       [ 1.4622614 ,  0.18845219, -0.93592448, ..., -1.21881681,\n",
       "        -1.05550571, -0.99742673],\n",
       "       [ 1.54746534,  1.41017268, -0.75276352, ..., -1.21881681,\n",
       "        -0.424724  , -0.75990586],\n",
       "       ...,\n",
       "       [-0.66519163,  0.18845219, -0.55282109, ...,  2.34855346,\n",
       "        -0.12435176, -0.64429836],\n",
       "       [ 0.80898128, -1.0332683 , -0.75433357, ...,  2.34855346,\n",
       "        -0.57491012, -0.73117915],\n",
       "       [ 1.27782757, -2.25498879, -0.10684869, ...,  2.34855346,\n",
       "         0.05587158, -0.23441721]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이게 실수형 데이터 들\n",
    "input_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 모델 파라미터 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * y : 수입이 50k 초과인지 아닌지\n",
    " * 초과면 1, 아니면 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구현에 대한 간단한 설명을 하겠습니다.  \n",
    "입력은 2개로 분리해서 생각하면 됩니다.  \n",
    "\n",
    "Wide 모델의 입력: category Feature을 Polynomial하게 바꿔준 데이터  \n",
    "Deep 모델의 입력: category Feature을 embeding 시켜준 데이터 + continuous한 데이터  \n",
    "\n",
    "그리고 출력은 lgbm 모델과 마찬가지로 1058개의 prediction 값이 row만큼 출력 됩니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(y_true, y_pred):\n",
    "    true = K.equal(y_true, 1.0 ) \n",
    "    pred = K.greater(y_pred , 0.5)\n",
    "    true2 = K.cast(true , dtype = float)\n",
    "    pred2 = K.cast(pred , dtype = float)\n",
    "    return  K.sum(true2 * pred2) / K.sum(true2) \n",
    "\n",
    "gamma = 2.0\n",
    "epsilon = K.epsilon()\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    # https://www.kaggle.com/mathormad/resnet50-v2-keras-focal-loss-mix-up\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    FL = K.pow(1-pt, gamma) * CE\n",
    "    loss = K.sum(FL, axis=1)\n",
    "    return loss\n",
    "    return K.mean(K.sum(loss, axis=1))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=focal_loss   , # focal_loss  ,  # 'binary_crossentropy',\n",
    "              metrics=[ binary_accuracy ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/ckpt/my_checkpoint/KM-{epoch:04d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 save_best_only = True , \n",
    "                                                 save_freq = 'epoch' , \n",
    "                                                 verbose=1)\n",
    "# https://www.kaggle.com/rejpalcz/focalloss-for-keras\n",
    "def step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=10):\n",
    "    '''\n",
    "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
    "    '''\n",
    "    def schedule(epoch):\n",
    "        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
    "    \n",
    "    return tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "\n",
    "lr_sched = step_decay_schedule(initial_lr=1e-4, decay_factor=0.75, step_size=2)\n",
    "\n",
    "  # `val_loss`가 2번의 에포크에 걸쳐 향상되지 않으면 훈련을 멈춥니다.\n",
    "Early = tf.keras.callbacks.EarlyStopping(min_delta=0.0001, \n",
    "                                         patience=10 ,\n",
    "                                         monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88628, 7)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "575/589 [============================>.] - ETA: 0s - loss: 5.0482 - binary_accuracy: 0.0045\n",
      "Epoch 00001: val_loss improved from inf to 2.20302, saving model to ./data/wide-deep.h5\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 4.9808 - binary_accuracy: 0.0044 - val_loss: 2.2030 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "586/589 [============================>.] - ETA: 0s - loss: 2.0641 - binary_accuracy: 5.8660e-04\n",
      "Epoch 00002: val_loss improved from 2.20302 to 2.14471, saving model to ./data/wide-deep.h5\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 2.0640 - binary_accuracy: 5.8362e-04 - val_loss: 2.1447 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "586/589 [============================>.] - ETA: 0s - loss: 2.0178 - binary_accuracy: 9.3323e-04\n",
      "Epoch 00003: val_loss improved from 2.14471 to 2.14277, saving model to ./data/wide-deep.h5\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 2.0178 - binary_accuracy: 9.2848e-04 - val_loss: 2.1428 - val_binary_accuracy: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "588/589 [============================>.] - ETA: 0s - loss: 1.9958 - binary_accuracy: 0.0016\n",
      "Epoch 00004: val_loss did not improve from 2.14277\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 1.9958 - binary_accuracy: 0.0016 - val_loss: 2.1500 - val_binary_accuracy: 7.5120e-05\n",
      "Epoch 5/1000\n",
      "567/589 [===========================>..] - ETA: 0s - loss: 1.9808 - binary_accuracy: 0.0017\n",
      "Epoch 00005: val_loss did not improve from 2.14277\n",
      "589/589 [==============================] - 1s 3ms/step - loss: 1.9806 - binary_accuracy: 0.0018 - val_loss: 2.1532 - val_binary_accuracy: 7.5120e-05\n",
      "Epoch 6/1000\n",
      "589/589 [==============================] - ETA: 0s - loss: 1.9647 - binary_accuracy: 0.0024\n",
      "Epoch 00006: val_loss did not improve from 2.14277\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 1.9647 - binary_accuracy: 0.0024 - val_loss: 2.1725 - val_binary_accuracy: 1.5024e-04\n",
      "Epoch 7/1000\n",
      "573/589 [============================>.] - ETA: 0s - loss: 1.9496 - binary_accuracy: 0.0025\n",
      "Epoch 00007: val_loss did not improve from 2.14277\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 1.9502 - binary_accuracy: 0.0025 - val_loss: 2.2070 - val_binary_accuracy: 3.0048e-04\n",
      "Epoch 8/1000\n",
      "589/589 [==============================] - ETA: 0s - loss: 1.9361 - binary_accuracy: 0.0030\n",
      "Epoch 00008: val_loss did not improve from 2.14277\n",
      "589/589 [==============================] - 2s 3ms/step - loss: 1.9361 - binary_accuracy: 0.0030 - val_loss: 2.2605 - val_binary_accuracy: 7.5120e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff8b7b58290>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_data, train_y, epochs=epochs, batch_size=batch_size, validation_split=0.15, callbacks=[checkpoint, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wide & Deep 모델에서는 구매 품목의 imbalance 문제를 해결하기 위해서 focal loss를 도입했습니다.  \n",
    "focal loss는 많은 비중을 차지해서 비교적 잘 분류되는 품목에는 영향력을 줄여주어서 분류가 잘 되지 않는 품목에 집중할 수 있도록 도와줍니다.  \n",
    "직접 아웃풋을 분석한 결과 Focal loss를 사용하기 전에는 구매율이 높은 품목들만 추천했다면, 도입한 뒤로는 좀 더 다양한 추천을 해주는 것 같습니다. 하지만 아직 정확도가 낮은 문제점이 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train input data와 같은 방식으로 test data를 input 형식에 맞추어줌\n",
    "eval_input_data = [test_x_continue] + [test_x_category[:, i] for i in range(test_x_category.shape[1])] + [test_x_category_poly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770/770 [==============================] - 1s 988us/step - loss: 2.7854 - binary_accuracy: 5.6818e-04\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(eval_input_data, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 2.785388469696045 - test_acc: 0.0005681818001903594\n"
     ]
    }
   ],
   "source": [
    "print(f'test_loss: {loss} - test_acc: {acc}')\n",
    "# 문자열 앞에 f는 formating이었나? 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = model.predict(eval_input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "pred_matrix: 예측된 아이템 행렬 파라미터.\n",
    "top_n: 상위 몇개를 추천으로 사용할 지 정하는 파라미터.\n",
    "test_matix: 고객ID와 Target이 있는 행렬 파라미터\n",
    "'''\n",
    "def get_acc(score_matrix, top_n, test_matix):\n",
    "    avg_acc = 0\n",
    "    for i in range(len(score_matrix)):\n",
    "        top = score_matrix.iloc[i].nlargest(top_n).index\n",
    "        tmp = 0\n",
    "        for j in range(len(top)):\n",
    "            if top[j] == test_matix[\"target\"][i]:\n",
    "                tmp += 1\n",
    "        acc = tmp / len(top)\n",
    "        avg_acc += acc / len(score_matrix)\n",
    "\n",
    "    return avg_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42301</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29233</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58449</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48924</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47681</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clnt_id  target\n",
       "0    42301     647\n",
       "1    29233     775\n",
       "2    58449     364\n",
       "3    48924     364\n",
       "4    47681     647"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {'clnt_id': test_x['clnt_id'],'target' : test_x['clac_nm3']}\n",
    "target_matrix = pd.DataFrame(dic).reset_index()\n",
    "target_matrix = target_matrix.drop(['index'], axis=1)\n",
    "\n",
    "target_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1045</th>\n",
       "      <th>1046</th>\n",
       "      <th>1047</th>\n",
       "      <th>1048</th>\n",
       "      <th>1049</th>\n",
       "      <th>1050</th>\n",
       "      <th>1051</th>\n",
       "      <th>1052</th>\n",
       "      <th>1053</th>\n",
       "      <th>1054</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003870</td>\n",
       "      <td>0.009187</td>\n",
       "      <td>0.013846</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.050542</td>\n",
       "      <td>0.012555</td>\n",
       "      <td>0.017187</td>\n",
       "      <td>0.040968</td>\n",
       "      <td>0.066419</td>\n",
       "      <td>0.032210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>0.009276</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.054420</td>\n",
       "      <td>0.004990</td>\n",
       "      <td>0.016043</td>\n",
       "      <td>0.002339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015519</td>\n",
       "      <td>0.007073</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>0.004541</td>\n",
       "      <td>0.086528</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.049089</td>\n",
       "      <td>0.037475</td>\n",
       "      <td>0.037094</td>\n",
       "      <td>0.049752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.002363</td>\n",
       "      <td>0.027529</td>\n",
       "      <td>0.002927</td>\n",
       "      <td>0.103238</td>\n",
       "      <td>0.018922</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>0.002350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.048368</td>\n",
       "      <td>0.045424</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.090145</td>\n",
       "      <td>0.016341</td>\n",
       "      <td>0.086308</td>\n",
       "      <td>0.094145</td>\n",
       "      <td>0.137432</td>\n",
       "      <td>0.054816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>0.001550</td>\n",
       "      <td>0.045851</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.096974</td>\n",
       "      <td>0.003262</td>\n",
       "      <td>0.068804</td>\n",
       "      <td>0.004877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.022368</td>\n",
       "      <td>0.008663</td>\n",
       "      <td>0.030572</td>\n",
       "      <td>0.006060</td>\n",
       "      <td>0.073585</td>\n",
       "      <td>0.004553</td>\n",
       "      <td>0.042916</td>\n",
       "      <td>0.029611</td>\n",
       "      <td>0.041933</td>\n",
       "      <td>0.058360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.001469</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.029728</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.108355</td>\n",
       "      <td>0.019072</td>\n",
       "      <td>0.006630</td>\n",
       "      <td>0.002142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.062453</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.026579</td>\n",
       "      <td>0.022882</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>0.009927</td>\n",
       "      <td>0.007433</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>0.028880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004389</td>\n",
       "      <td>0.015503</td>\n",
       "      <td>0.005152</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.021648</td>\n",
       "      <td>0.001776</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.079559</td>\n",
       "      <td>0.000965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1055 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.003870  0.009187  0.013846  0.001066  0.050542  0.012555  0.017187   \n",
       "1  0.015519  0.007073  0.029056  0.004541  0.086528  0.004747  0.049089   \n",
       "2  0.001252  0.048368  0.045424  0.000945  0.090145  0.016341  0.086308   \n",
       "3  0.022368  0.008663  0.030572  0.006060  0.073585  0.004553  0.042916   \n",
       "4  0.060900  0.062453  0.007792  0.026579  0.022882  0.006127  0.009927   \n",
       "\n",
       "       7         8         9     ...      1045      1046      1047      1048  \\\n",
       "0  0.040968  0.066419  0.032210  ...  0.001556  0.003507  0.001765  0.006174   \n",
       "1  0.037475  0.037094  0.049752  ...  0.002761  0.001996  0.004467  0.002363   \n",
       "2  0.094145  0.137432  0.054816  ...  0.001171  0.003011  0.005142  0.001550   \n",
       "3  0.029611  0.041933  0.058360  ...  0.001998  0.001469  0.003201  0.002157   \n",
       "4  0.007433  0.020697  0.028880  ...  0.004389  0.015503  0.005152  0.001835   \n",
       "\n",
       "       1049      1050      1051      1052      1053      1054  \n",
       "0  0.009276  0.002257  0.054420  0.004990  0.016043  0.002339  \n",
       "1  0.027529  0.002927  0.103238  0.018922  0.008862  0.002350  \n",
       "2  0.045851  0.002800  0.096974  0.003262  0.068804  0.004877  \n",
       "3  0.029728  0.002877  0.108355  0.019072  0.006630  0.002142  \n",
       "4  0.021648  0.001776  0.030017  0.009923  0.079559  0.000965  \n",
       "\n",
       "[5 rows x 1055 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_p = pd.DataFrame(predict_y[:1000])\n",
    "small_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 2.0999999999999983%\n"
     ]
    }
   ],
   "source": [
    "accuracy  = get_acc(small_p, 5, target_matrix)\n",
    "\n",
    "print(f\"정확도: {accuracy*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_list(predict_y, top_n, target_matrix, columns):\n",
    "    test_matrix = target_matrix.copy()\n",
    "    pred_matrix = predict_y.copy()\n",
    "    pred_matrix.rename(columns = columns['hangle'], inplace = True)\n",
    "    for i in range(len(pred_matrix)):\n",
    "        top = pred_matrix.iloc[i].nlargest(top_n).index\n",
    "        top = pd.DataFrame(top.astype(str).to_frame().apply(lambda x: \", \".join(x)))\n",
    "        test_matrix.loc[i, 'pred'] = top.values\n",
    "    test_matrix['target'] = test_matrix['target'].apply(lambda x: columns['hangle'][x])\n",
    "    return test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'hangle': Input['clac_nm3'], 'label': data['clac_nm3']}\n",
    "df = pd.DataFrame(data=d).drop_duplicates()\n",
    "cate2papago = df.set_index('label').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_pred_list(small_p, 5, target_matrix, cate2papago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42301</td>\n",
       "      <td>여자 로퍼</td>\n",
       "      <td>[여자 골프 의류 세트, 여성 가죽 의류, 키즈 우산, 스포츠 가방, 치즈'!]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29233</td>\n",
       "      <td>제너럴 요구르트</td>\n",
       "      <td>[즉석 죽, 포도, 국내 Beefs-Rounds, 옥수수 스낵, 우유]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58449</td>\n",
       "      <td>밤</td>\n",
       "      <td>[포도, 아기 매트리스 패드, 냉동 떡볶이, 냉동 튀김 식품, 라면]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48924</td>\n",
       "      <td>밤</td>\n",
       "      <td>[옥수수 스낵, 즉석 죽, 제너럴 티 드링크, 국내 Beefs-Rounds, 포도]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47681</td>\n",
       "      <td>여자 로퍼</td>\n",
       "      <td>[여자 로퍼, 여성 청바지, 펫 도그 푸드, 조리 기구 세트, 여성 가죽 의류]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>16419</td>\n",
       "      <td>여성 스웨터 / 풀오버</td>\n",
       "      <td>[남성 정장, 여성 청바지, 기타 컴퓨터 액세서리, 다른 영양학적 Supplemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>70886</td>\n",
       "      <td>팬케이크 믹스</td>\n",
       "      <td>[옥수수 스낵, 국내 Beefs-Rounds, 라면, 즉석 죽, 제너럴 티 드링크]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>16419</td>\n",
       "      <td>여성 스웨터 / 풀오버</td>\n",
       "      <td>[남성 정장, 여성 청바지, 기타 컴퓨터 액세서리, 다른 영양학적 Supplemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>47330</td>\n",
       "      <td>기능성 우유</td>\n",
       "      <td>[즉석 죽, 옥수수 스낵, 포도, 일반 스낵, 라면]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>13871</td>\n",
       "      <td>인공조미료</td>\n",
       "      <td>[즉석 죽, 포도, 국내 Porks-Picnics, 라면, 옥수수 스낵]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     clnt_id        target                                               pred\n",
       "0      42301         여자 로퍼       [여자 골프 의류 세트, 여성 가죽 의류, 키즈 우산, 스포츠 가방, 치즈'!]\n",
       "1      29233      제너럴 요구르트            [즉석 죽, 포도, 국내 Beefs-Rounds, 옥수수 스낵, 우유]\n",
       "2      58449             밤             [포도, 아기 매트리스 패드, 냉동 떡볶이, 냉동 튀김 식품, 라면]\n",
       "3      48924             밤     [옥수수 스낵, 즉석 죽, 제너럴 티 드링크, 국내 Beefs-Rounds, 포도]\n",
       "4      47681         여자 로퍼       [여자 로퍼, 여성 청바지, 펫 도그 푸드, 조리 기구 세트, 여성 가죽 의류]\n",
       "..       ...           ...                                                ...\n",
       "995    16419  여성 스웨터 / 풀오버  [남성 정장, 여성 청바지, 기타 컴퓨터 액세서리, 다른 영양학적 Supplemen...\n",
       "996    70886       팬케이크 믹스     [옥수수 스낵, 국내 Beefs-Rounds, 라면, 즉석 죽, 제너럴 티 드링크]\n",
       "997    16419  여성 스웨터 / 풀오버  [남성 정장, 여성 청바지, 기타 컴퓨터 액세서리, 다른 영양학적 Supplemen...\n",
       "998    47330        기능성 우유                      [즉석 죽, 옥수수 스낵, 포도, 일반 스낵, 라면]\n",
       "999    13871         인공조미료           [즉석 죽, 포도, 국내 Porks-Picnics, 라면, 옥수수 스낵]\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['pred'].notna()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
