{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide & Deep Learning model 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저희는 추천 시스템을 적용하기 위해서 `Wide & Deep` 모델을 사용했습니다. \n",
    "\n",
    "모델 구현에 대한 간단한 설명을 하겠습니다.  \n",
    "입력은 2개로 분리해서 생각하면 됩니다.  \n",
    "\n",
    "`Wide 모델`의 입력: category Feature을 `Polynomial`하게 바꿔준 데이터  \n",
    "`Deep 모델`의 입력: category Feature을 `embeding` 시켜준 데이터 + `continuous`한 데이터   \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3147: DtypeWarning: Columns (37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>sess_id</th>\n",
       "      <th>hit_seq</th>\n",
       "      <th>action_type</th>\n",
       "      <th>biz_unit</th>\n",
       "      <th>sess_dt</th>\n",
       "      <th>hit_tm</th>\n",
       "      <th>hit_pss_tm</th>\n",
       "      <th>trans_id</th>\n",
       "      <th>sech_kwd</th>\n",
       "      <th>...</th>\n",
       "      <th>holiday</th>\n",
       "      <th>hour</th>\n",
       "      <th>prefer_dvc_trfc</th>\n",
       "      <th>hum</th>\n",
       "      <th>temp</th>\n",
       "      <th>pty</th>\n",
       "      <th>r06</th>\n",
       "      <th>clac_nm2</th>\n",
       "      <th>clnt_gender</th>\n",
       "      <th>clnt_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121082</th>\n",
       "      <td>3390</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A01</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>지고트</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile_app_DIRECT</td>\n",
       "      <td>59.0</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Women's Outwear</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194580</th>\n",
       "      <td>5535</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>A03</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>6532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile_app_DIRECT</td>\n",
       "      <td>59.0</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194581</th>\n",
       "      <td>5535</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A03</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>30494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>양파</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile_app_DIRECT</td>\n",
       "      <td>59.0</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chilled Instant Foods</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194582</th>\n",
       "      <td>5535</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A03</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>32370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile_app_DIRECT</td>\n",
       "      <td>59.0</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Chilled Beverages</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194583</th>\n",
       "      <td>5535</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A03</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>41637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>우엉</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mobile_app_DIRECT</td>\n",
       "      <td>59.0</td>\n",
       "      <td>24.700001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Snacks</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        clnt_id  sess_id  hit_seq  action_type biz_unit     sess_dt hit_tm  \\\n",
       "121082     3390        1        1            0      A01  2019-07-01  00:00   \n",
       "194580     5535        1        1            5      A03  2019-07-01  00:00   \n",
       "194581     5535        1        2            0      A03  2019-07-01  00:00   \n",
       "194582     5535        1        3            3      A03  2019-07-01  00:00   \n",
       "194583     5535        1        4            0      A03  2019-07-01  00:00   \n",
       "\n",
       "        hit_pss_tm  trans_id sech_kwd  ...  holiday  hour    prefer_dvc_trfc  \\\n",
       "121082           0       NaN      지고트  ...        0     0  mobile_app_DIRECT   \n",
       "194580        6532       NaN      NaN  ...        0     0  mobile_app_DIRECT   \n",
       "194581       30494       NaN       양파  ...        0     0  mobile_app_DIRECT   \n",
       "194582       32370       NaN      NaN  ...        0     0  mobile_app_DIRECT   \n",
       "194583       41637       NaN       우엉  ...        0     0  mobile_app_DIRECT   \n",
       "\n",
       "         hum       temp  pty  r06               clac_nm2  clnt_gender  \\\n",
       "121082  59.0  24.700001  0.0  0.0        Women's Outwear      unknown   \n",
       "194580  59.0  24.700001  0.0  0.0                    NaN            F   \n",
       "194581  59.0  24.700001  0.0  0.0  Chilled Instant Foods            F   \n",
       "194582  59.0  24.700001  0.0  0.0      Chilled Beverages            F   \n",
       "194583  59.0  24.700001  0.0  0.0                 Snacks            F   \n",
       "\n",
       "        clnt_age  \n",
       "121082   unknown  \n",
       "194580        30  \n",
       "194581        30  \n",
       "194582        30  \n",
       "194583        30  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = pd.read_csv('./data/Total_Data_1.csv')\n",
    "df_merge = df_merge[['clnt_id', 'sess_id', 'hit_seq', 'action_type', 'biz_unit', 'sess_dt',\n",
    "       'hit_tm', 'hit_pss_tm', 'trans_id', 'sech_kwd', 'tot_pag_view_ct',\n",
    "       'tot_sess_hr_v', 'trfc_src', 'dvc_ctg_nm', 'cum_act_0', 'cum_act_1',\n",
    "       'cum_act_2', 'cum_act_3', 'cum_act_4', 'cum_act_5', 'cum_act_6','sech_clac_nm2',\n",
    "       'cum_act_7', 'day', 'holiday', 'hour', 'prefer_dvc_trfc', 'hum', 'temp',\n",
    "       'pty', 'r06', 'clac_nm2','clnt_gender', 'clnt_age']]\n",
    "\n",
    "df_merge = df_merge.sort_values(['sess_dt', 'hit_tm'])\n",
    "df_merge.loc[df_merge['clac_nm2'].isnull(),'clac_nm2'] = df_merge['sech_clac_nm2']\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_add_nm0 = pd.read_csv('./data/item_add_nm0.csv')\n",
    "item_add_nm0 = item_add_nm0[['pd_c', 'clac_nm1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_add_nm0['pd_c'] = item_add_nm0['pd_c'].astype(np.float).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>trans_id</th>\n",
       "      <th>trans_seq</th>\n",
       "      <th>biz_unit</th>\n",
       "      <th>pd_c</th>\n",
       "      <th>de_dt</th>\n",
       "      <th>de_tm</th>\n",
       "      <th>buy_am</th>\n",
       "      <th>buy_ct</th>\n",
       "      <th>clac_nm1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>42449.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A02</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>20190704</td>\n",
       "      <td>15:34</td>\n",
       "      <td>46430</td>\n",
       "      <td>1</td>\n",
       "      <td>Men's Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>62037.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A03</td>\n",
       "      <td>92.0</td>\n",
       "      <td>20190729</td>\n",
       "      <td>23:47</td>\n",
       "      <td>36000</td>\n",
       "      <td>20</td>\n",
       "      <td>Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>64691.0</td>\n",
       "      <td>1</td>\n",
       "      <td>A03</td>\n",
       "      <td>186.0</td>\n",
       "      <td>20190731</td>\n",
       "      <td>21:25</td>\n",
       "      <td>3790</td>\n",
       "      <td>1</td>\n",
       "      <td>Chilled Foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>64691.0</td>\n",
       "      <td>2</td>\n",
       "      <td>A03</td>\n",
       "      <td>151.0</td>\n",
       "      <td>20190731</td>\n",
       "      <td>21:25</td>\n",
       "      <td>3990</td>\n",
       "      <td>1</td>\n",
       "      <td>Canned / Jarred Foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>64691.0</td>\n",
       "      <td>3</td>\n",
       "      <td>A03</td>\n",
       "      <td>351.0</td>\n",
       "      <td>20190731</td>\n",
       "      <td>21:25</td>\n",
       "      <td>4690</td>\n",
       "      <td>1</td>\n",
       "      <td>Dairy Products</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clnt_id  trans_id  trans_seq biz_unit    pd_c     de_dt  de_tm  buy_am  \\\n",
       "0        2   42449.0          1      A02  1015.0  20190704  15:34   46430   \n",
       "1        2   62037.0          1      A03    92.0  20190729  23:47   36000   \n",
       "2        2   64691.0          1      A03   186.0  20190731  21:25    3790   \n",
       "3        2   64691.0          2      A03   151.0  20190731  21:25    3990   \n",
       "4        2   64691.0          3      A03   351.0  20190731  21:25    4690   \n",
       "\n",
       "   buy_ct               clac_nm1  \n",
       "0       1         Men's Clothing  \n",
       "1      20              Beverages  \n",
       "2       1          Chilled Foods  \n",
       "3       1  Canned / Jarred Foods  \n",
       "4       1         Dairy Products  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_trade = trade.merge(item_add_nm0, how = 'left')\n",
    "df3_trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_3 = pd.merge(df2_online, \n",
    "                     df3_trade, \n",
    "                on='trans_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_3 = sample_3[sample_3['clac_nm1'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_3 = sample_3.sort_values('clac_nm1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## label이 있는 행 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구매 이력이 있는 행: 24.55 %\n"
     ]
    }
   ],
   "source": [
    "df_buyer = df_merge[(df_merge['action_type']==0)|(df_merge['action_type']==6)]\n",
    "print('구매 이력이 있는 행:', round(len(df_buyer['clac_nm2']) / len(df_merge['clac_nm2']) * 100, 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User2Vec 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저 임베딩 데이터 load\n",
    "user2vec = pd.read_csv('./data/user2vec100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buyer = df_buyer[df_buyer['clac_nm2'].notna()]\n",
    "df_buyer = df_buyer.merge(user2vec, on=['clnt_id', 'sess_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_buyer.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col=['clnt_id', 'sess_id', 'hit_seq', 'action_type', 'hit_tm', 'trans_id','sech_clac_nm2', 'sess_dt', 'sech_kwd']\n",
    "df_buyer = df_buyer.drop(drop_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br><br>\n",
    "## label 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "lab_len = len(df_buyer['clac_nm2'].value_counts())\n",
    "label_key = df_buyer['clac_nm2'].value_counts().keys()\n",
    "\n",
    "df_buyer['clac_nm2'] = le.fit_transform(df_buyer['clac_nm2'])\n",
    "clac_nm2 = df_buyer['clac_nm2'].copy()\n",
    "df_buyer.drop(['clac_nm2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = []\n",
    "for i in range(100):\n",
    "    x_col.append('X_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_COLUMNS = [\n",
    "    'biz_unit', 'hit_pss_tm', 'tot_pag_view_ct', 'tot_sess_hr_v',  \n",
    "       'trfc_src', 'dvc_ctg_nm', 'cum_act_0', 'cum_act_1', 'cum_act_2',\n",
    "       'cum_act_3', 'cum_act_4', 'cum_act_5', 'cum_act_6', 'cum_act_7', 'day',\n",
    "       'holiday', 'hour', 'prefer_dvc_trfc', 'hum', 'temp', 'pty', 'r06',\n",
    "       'clnt_gender', 'clnt_age'\n",
    "]\n",
    "\n",
    "CATEGORICAL_COLUMNS = [\n",
    "    \"biz_unit\", 'trfc_src', 'dvc_ctg_nm',  \n",
    "    'prefer_dvc_trfc', 'clnt_gender', 'clnt_age', 'pty'\n",
    "]\n",
    "\n",
    "EMBEDDED_COLUMNS = x_col\n",
    "\n",
    "CONTINUOUS_COLUMNS = list(set(ALL_COLUMNS).difference(CATEGORICAL_COLUMNS+EMBEDDED_COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buyer.loc[df_buyer['clnt_gender'].isnull(),'clnt_gender'] = 'U'\n",
    "df_buyer.loc[df_buyer['clnt_age'].isnull(),'clnt_age'] =  -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in CATEGORICAL_COLUMNS:\n",
    "    le = LabelEncoder()\n",
    "    df_buyer[c] = le.fit_transform(df_buyer[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = clac_nm2.copy()\n",
    "label = np.eye(lab_len)[label]\n",
    "label = pd.DataFrame(data=label, columns=label_key, index=df_buyer.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Train 데이터, Test 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x , train_y , test_y = train_test_split(df_buyer , label , test_size=0.05, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터:  (626819, 124)\n",
      "Test 데이터:  (32991, 124)\n",
      "Train 라벨:  (626819, 309)\n",
      "Test 라벨:  (32991, 309)\n"
     ]
    }
   ],
   "source": [
    "print('Train 데이터: ', train_x.shape)\n",
    "print('Test 데이터: ', test_x.shape)\n",
    "print('Train 라벨: ', train_y.shape)\n",
    "print('Test 라벨: ', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x , train_y , val_y = train_test_split(train_x , train_y , test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터:  (564137, 124)\n",
      "Val 데이터:  (62682, 124)\n",
      "Train 라벨:  (564137, 309)\n",
      "Val 라벨:  (62682, 309)\n"
     ]
    }
   ],
   "source": [
    "print('Train 데이터: ', train_x.shape)\n",
    "print('Val 데이터: ', val_x.shape)\n",
    "print('Train 라벨: ', train_y.shape)\n",
    "print('Val 라벨: ', val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Column 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_category = np.array(train_x[CATEGORICAL_COLUMNS])\n",
    "test_x_category  = np.array(test_x[CATEGORICAL_COLUMNS])\n",
    "val_x_category   = np.array(val_x[CATEGORICAL_COLUMNS])\n",
    "\n",
    "train_x_embedding = np.array(train_x[EMBEDDED_COLUMNS])\n",
    "test_x_embedding  = np.array(test_x[EMBEDDED_COLUMNS])\n",
    "val_x_embedding   = np.array(val_x[EMBEDDED_COLUMNS])\n",
    "\n",
    "train_x_continue = np.array(train_x[CONTINUOUS_COLUMNS], dtype='float64')\n",
    "test_x_continue = np.array(test_x[CONTINUOUS_COLUMNS], dtype='float64')\n",
    "val_x_continue = np.array(val_x[CONTINUOUS_COLUMNS], dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_x_continue = scaler.fit_transform(train_x_continue)\n",
    "test_x_continue = scaler.transform(test_x_continue)\n",
    "val_x_continue = scaler.transform(val_x_continue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 정규화 내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.605023918592606\n",
      "-11.354365361540133\n",
      "-11.324531784106052\n",
      "-11.31247193416602\n",
      "-11.302824361617715\n"
     ]
    }
   ],
   "source": [
    "print(train_x_continue[0].sum())\n",
    "print(train_x_continue[1].sum())\n",
    "print(train_x_continue[2].sum())\n",
    "print(train_x_continue[3].sum())\n",
    "print(train_x_continue[4].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Polynomial 적용\n",
    "    - 카테고리 값을 Polynomial로 바꿔줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sklearn.preprocessing.PolynomialFeatures 메소드\n",
    "    - degree : 다항식 차수\n",
    "    - interaction_only\n",
    "        - default는 False\n",
    "        - ex) degree = 3일 때, interaction_only=false 이면\n",
    "            - a^2, a^3, b^2, b^3, ab, a^2*b, ab^2 Feature가 추가되고,\n",
    "        - interaction_only=True 이면\n",
    "            - ab만 추가됨\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_category_poly = poly.fit_transform(train_x_category)\n",
    "test_x_category_poly = poly.fit_transform(test_x_category)\n",
    "val_x_category_poly = poly.fit_transform(val_x_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564137, 29)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_category_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구현에 대한 간단한 설명을 하겠습니다.  \n",
    "입력은 2개로 분리해서 생각하면 됩니다.  \n",
    "\n",
    "Wide 모델의 입력: category Feature을 Polynomial하게 바꿔준 데이터  \n",
    "Deep 모델의 입력: category Feature을 embeding 시켜준 데이터 + continuous한 데이터  \n",
    "\n",
    "그리고 출력은 lgbm 모델과 마찬가지로 1058개의 prediction 값이 row만큼 출력 됩니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.keras.layers.advanced_activations import ReLU, PReLU, LeakyReLU, ELU\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.keras.models import Model\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 0.9\n",
    "lr = 1e-5\n",
    "l1 = 0.01\n",
    "l2 = 0.01\n",
    "momentum = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_model():\n",
    "    \n",
    "    category_inputs = []\n",
    "    category_embeds = []\n",
    "    \n",
    "    # Categorical Data Embedding\n",
    "    for i in range(len(CATEGORICAL_COLUMNS)):\n",
    "        \n",
    "        # input - embedding - flatten 순으로 layer 쌓기\n",
    "        input_i = Input(shape=(1,), dtype='int32')\n",
    "        \n",
    "        dim = len(np.unique(df_buyer[CATEGORICAL_COLUMNS[i]]))\n",
    "        \n",
    "        embed_dim = int(np.ceil(dim ** 0.5))\n",
    "        \n",
    "        embed_i = Embedding(dim, embed_dim, input_length=1)(input_i)\n",
    "        # dim : 데이터가 몇 종류 있는지 = 임베딩 벡터를 몇 개 뽑아낼 것인지\n",
    "        # embed_dim : 임베딩 처리 후 벡터의 차원 = 임베딩 벡터를 몇 차원 벡터로 뽑아 낼 것인지\n",
    "        # input_length : 입력 데이터 길이\n",
    "        \n",
    "        flatten_i = Flatten()(embed_i)\n",
    "        # category 값을 임베딩환 벡터들을 flatten\n",
    "        \n",
    "        category_inputs.append(input_i)\n",
    "        category_embeds.append(flatten_i)\n",
    "        \n",
    "    # continuous 데이터 input\n",
    "    continue_input = Input(shape=(len(CONTINUOUS_COLUMNS),))\n",
    "    continue_dense = Dense(256, use_bias=False)(continue_input)\n",
    "    \n",
    "    # category와 continue를 합침\n",
    "    concat_embeds = concatenate([continue_dense] + category_embeds)\n",
    "    concat_embeds = Activation('relu')(concat_embeds)\n",
    "    \n",
    "    bn_concat = BatchNormalization(momentum=momentum)( concat_embeds)\n",
    "    \n",
    "    fc1 = Dense(512, use_bias=False)(bn_concat)\n",
    "    relu1 = ReLU()(fc1)\n",
    "    bn1 = BatchNormalization()(relu1)\n",
    "    fc2 = Dense(256, use_bias=False)(bn1)\n",
    "    relu2 = ReLU()(fc2)\n",
    "    bn2 = BatchNormalization()(relu2)\n",
    "    fc3 = Dense(128)(bn2)\n",
    "    deep = ReLU()(fc3)\n",
    "    \n",
    "    return category_inputs, continue_input, deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_category_poly : 카테고리 데이터를 숫자로 바꾸고, Poly Feature를 추가한 것\n",
    "# Poly Feature : a, b, c Feature를 이용해서 ab, bc, ca Feature를 만든것\n",
    "# 데이터의 shape 만 가져옴\n",
    "def get_wide_model(poly):\n",
    "    dim = poly.shape[1]\n",
    "    return tf.keras.layers.Input(shape=(dim,))\n",
    "\n",
    "def get_embed_model(embed):\n",
    "    dim = embed.shape[1]\n",
    "    return tf.keras.layers.Input(shape=(dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - embedding - flatten 순으로 layer 쌓기\n",
    "category_inputs, continue_input, deep_model = get_deep_model()\n",
    "wide_model = get_wide_model(train_x_category_poly)\n",
    "embed_model = get_embed_model(train_x_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Wide모델과 Deep model을 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = concatenate([deep_model, wide_model, embed_model])\n",
    "inputs = [continue_input] + category_inputs + [wide_model] + [embed_model]\n",
    "output = Dense(len(label_key), activation='sigmoid')(concat)\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 입력 데이터\n",
    "\n",
    "    * 위에서 정의한 리스트 변수 inputs에 맞추어\n",
    "    * continue 데이터 => category 데이터 => poly data 순으로 입력 값을 넣어준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [train_x_continue] + [train_x_category[:, i] \\\n",
    "             for i in range(train_x_category.shape[1])] + \\\n",
    "             [train_x_category_poly] + [train_x_embedding]\n",
    "\n",
    "val_data = [val_x_continue] + [val_x_category[:, i] \\\n",
    "            for i in range(val_x_category.shape[1])] + \\\n",
    "            [val_x_category_poly] + [val_x_embedding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(y_true, y_pred):\n",
    "    true = K.equal(y_true, 1.0 ) \n",
    "    true2 = K.cast(true , dtype = float)\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "gamma = 2.0\n",
    "epsilon = K.epsilon()\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    # https://www.kaggle.com/mathormad/resnet50-v2-keras-focal-loss-mix-up\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    FL = K.pow(1-pt, gamma) * CE\n",
    "    loss = K.sum(FL, axis=1)\n",
    "    return loss\n",
    "    return K.mean(K.sum(loss, axis=1))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr, beta_1=beta_1),\n",
    "              loss=focal_loss   , # focal_loss  ,  # 'binary_crossentropy',\n",
    "              metrics=[ binary_crossentropy ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./ckpt/my_checkpoint/KM-{epoch:04d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 save_best_only = True , \n",
    "                                                 save_freq = 'epoch' , \n",
    "                                                 mode='auto' ,\n",
    "                                                 verbose=1)\n",
    "# step 별로 learning rate를 조절합니다. \n",
    "def step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=10):\n",
    "    def schedule(epoch):\n",
    "        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
    "    \n",
    "    return tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "\n",
    "lr_sched = step_decay_schedule(initial_lr=lr, decay_factor=0.8, step_size=2)\n",
    "\n",
    "  # `val_loss`가 2번의 에포크에 걸쳐 향상되지 않으면 훈련을 멈춥니다.\n",
    "Early = tf.keras.callbacks.EarlyStopping(min_delta=0.0001, \n",
    "                                         patience=10 ,\n",
    "                                         monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4401/4408 [============================>.] - ETA: 0s - loss: 48.6831 - binary_crossentropy: 0.3033\n",
      "Epoch 00001: val_loss improved from inf to 2.92667, saving model to ./ckpt/my_checkpoint/KM-0001.ckpt\n",
      "WARNING:tensorflow:From /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0001.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 48.6174 - binary_crossentropy: 0.3029 - val_loss: 2.9267 - val_binary_crossentropy: 0.0716\n",
      "Epoch 2/500\n",
      "4395/4408 [============================>.] - ETA: 0s - loss: 2.4129 - binary_crossentropy: 0.0627\n",
      "Epoch 00002: val_loss improved from 2.92667 to 2.13889, saving model to ./ckpt/my_checkpoint/KM-0002.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0002.ckpt/assets\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 2.4123 - binary_crossentropy: 0.0627 - val_loss: 2.1389 - val_binary_crossentropy: 0.0638\n",
      "Epoch 3/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.9988 - binary_crossentropy: 0.0630\n",
      "Epoch 00003: val_loss improved from 2.13889 to 1.90021, saving model to ./ckpt/my_checkpoint/KM-0003.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0003.ckpt/assets\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.9986 - binary_crossentropy: 0.0630 - val_loss: 1.9002 - val_binary_crossentropy: 0.0640\n",
      "Epoch 4/500\n",
      "4400/4408 [============================>.] - ETA: 0s - loss: 1.8298 - binary_crossentropy: 0.0645\n",
      "Epoch 00004: val_loss improved from 1.90021 to 1.77941, saving model to ./ckpt/my_checkpoint/KM-0004.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0004.ckpt/assets\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.8297 - binary_crossentropy: 0.0645 - val_loss: 1.7794 - val_binary_crossentropy: 0.0646\n",
      "Epoch 5/500\n",
      "4400/4408 [============================>.] - ETA: 0s - loss: 1.7448 - binary_crossentropy: 0.0655\n",
      "Epoch 00005: val_loss improved from 1.77941 to 1.72220, saving model to ./ckpt/my_checkpoint/KM-0005.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0005.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.7448 - binary_crossentropy: 0.0655 - val_loss: 1.7222 - val_binary_crossentropy: 0.0652\n",
      "Epoch 6/500\n",
      "4400/4408 [============================>.] - ETA: 0s - loss: 1.6964 - binary_crossentropy: 0.0661\n",
      "Epoch 00006: val_loss improved from 1.72220 to 1.68162, saving model to ./ckpt/my_checkpoint/KM-0006.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0006.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.6964 - binary_crossentropy: 0.0661 - val_loss: 1.6816 - val_binary_crossentropy: 0.0652\n",
      "Epoch 7/500\n",
      "4391/4408 [============================>.] - ETA: 0s - loss: 1.6641 - binary_crossentropy: 0.0666\n",
      "Epoch 00007: val_loss improved from 1.68162 to 1.65858, saving model to ./ckpt/my_checkpoint/KM-0007.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0007.ckpt/assets\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.6641 - binary_crossentropy: 0.0666 - val_loss: 1.6586 - val_binary_crossentropy: 0.0655\n",
      "Epoch 8/500\n",
      "4391/4408 [============================>.] - ETA: 0s - loss: 1.6422 - binary_crossentropy: 0.0669\n",
      "Epoch 00008: val_loss improved from 1.65858 to 1.63914, saving model to ./ckpt/my_checkpoint/KM-0008.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0008.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.6422 - binary_crossentropy: 0.0669 - val_loss: 1.6391 - val_binary_crossentropy: 0.0662\n",
      "Epoch 9/500\n",
      "4408/4408 [==============================] - ETA: 0s - loss: 1.6254 - binary_crossentropy: 0.0671\n",
      "Epoch 00009: val_loss improved from 1.63914 to 1.62553, saving model to ./ckpt/my_checkpoint/KM-0009.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0009.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 4ms/step - loss: 1.6254 - binary_crossentropy: 0.0671 - val_loss: 1.6255 - val_binary_crossentropy: 0.0661\n",
      "Epoch 10/500\n",
      "4399/4408 [============================>.] - ETA: 0s - loss: 1.6135 - binary_crossentropy: 0.0673\n",
      "Epoch 00010: val_loss improved from 1.62553 to 1.61571, saving model to ./ckpt/my_checkpoint/KM-0010.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0010.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.6135 - binary_crossentropy: 0.0673 - val_loss: 1.6157 - val_binary_crossentropy: 0.0663\n",
      "Epoch 11/500\n",
      "4396/4408 [============================>.] - ETA: 0s - loss: 1.6029 - binary_crossentropy: 0.0674\n",
      "Epoch 00011: val_loss improved from 1.61571 to 1.60722, saving model to ./ckpt/my_checkpoint/KM-0011.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0011.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.6030 - binary_crossentropy: 0.0674 - val_loss: 1.6072 - val_binary_crossentropy: 0.0665\n",
      "Epoch 12/500\n",
      "4394/4408 [============================>.] - ETA: 0s - loss: 1.5956 - binary_crossentropy: 0.0675\n",
      "Epoch 00012: val_loss improved from 1.60722 to 1.60105, saving model to ./ckpt/my_checkpoint/KM-0012.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0012.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5956 - binary_crossentropy: 0.0675 - val_loss: 1.6011 - val_binary_crossentropy: 0.0665\n",
      "Epoch 13/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5887 - binary_crossentropy: 0.0675\n",
      "Epoch 00013: val_loss improved from 1.60105 to 1.59612, saving model to ./ckpt/my_checkpoint/KM-0013.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0013.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5887 - binary_crossentropy: 0.0675 - val_loss: 1.5961 - val_binary_crossentropy: 0.0662\n",
      "Epoch 14/500\n",
      "4400/4408 [============================>.] - ETA: 0s - loss: 1.5837 - binary_crossentropy: 0.0676\n",
      "Epoch 00014: val_loss improved from 1.59612 to 1.59094, saving model to ./ckpt/my_checkpoint/KM-0014.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0014.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5837 - binary_crossentropy: 0.0676 - val_loss: 1.5909 - val_binary_crossentropy: 0.0665\n",
      "Epoch 15/500\n",
      "4391/4408 [============================>.] - ETA: 0s - loss: 1.5788 - binary_crossentropy: 0.0676\n",
      "Epoch 00015: val_loss improved from 1.59094 to 1.58694, saving model to ./ckpt/my_checkpoint/KM-0015.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0015.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5789 - binary_crossentropy: 0.0676 - val_loss: 1.5869 - val_binary_crossentropy: 0.0665\n",
      "Epoch 16/500\n",
      "4395/4408 [============================>.] - ETA: 0s - loss: 1.5748 - binary_crossentropy: 0.0677\n",
      "Epoch 00016: val_loss improved from 1.58694 to 1.58388, saving model to ./ckpt/my_checkpoint/KM-0016.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0016.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5748 - binary_crossentropy: 0.0677 - val_loss: 1.5839 - val_binary_crossentropy: 0.0666\n",
      "Epoch 17/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5718 - binary_crossentropy: 0.0677\n",
      "Epoch 00017: val_loss improved from 1.58388 to 1.58103, saving model to ./ckpt/my_checkpoint/KM-0017.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0017.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5718 - binary_crossentropy: 0.0677 - val_loss: 1.5810 - val_binary_crossentropy: 0.0666\n",
      "Epoch 18/500\n",
      "4395/4408 [============================>.] - ETA: 0s - loss: 1.5687 - binary_crossentropy: 0.0677\n",
      "Epoch 00018: val_loss improved from 1.58103 to 1.57861, saving model to ./ckpt/my_checkpoint/KM-0018.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0018.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5687 - binary_crossentropy: 0.0677 - val_loss: 1.5786 - val_binary_crossentropy: 0.0665\n",
      "Epoch 19/500\n",
      "4397/4408 [============================>.] - ETA: 0s - loss: 1.5662 - binary_crossentropy: 0.0677\n",
      "Epoch 00019: val_loss improved from 1.57861 to 1.57675, saving model to ./ckpt/my_checkpoint/KM-0019.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0019.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5662 - binary_crossentropy: 0.0677 - val_loss: 1.5768 - val_binary_crossentropy: 0.0665\n",
      "Epoch 20/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5642 - binary_crossentropy: 0.0678\n",
      "Epoch 00020: val_loss improved from 1.57675 to 1.57557, saving model to ./ckpt/my_checkpoint/KM-0020.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0020.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5643 - binary_crossentropy: 0.0678 - val_loss: 1.5756 - val_binary_crossentropy: 0.0663\n",
      "Epoch 21/500\n",
      "4399/4408 [============================>.] - ETA: 0s - loss: 1.5626 - binary_crossentropy: 0.0677\n",
      "Epoch 00021: val_loss improved from 1.57557 to 1.57392, saving model to ./ckpt/my_checkpoint/KM-0021.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0021.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5626 - binary_crossentropy: 0.0677 - val_loss: 1.5739 - val_binary_crossentropy: 0.0667\n",
      "Epoch 22/500\n",
      "4408/4408 [==============================] - ETA: 0s - loss: 1.5606 - binary_crossentropy: 0.0677\n",
      "Epoch 00022: val_loss improved from 1.57392 to 1.57226, saving model to ./ckpt/my_checkpoint/KM-0022.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0022.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5606 - binary_crossentropy: 0.0677 - val_loss: 1.5723 - val_binary_crossentropy: 0.0666\n",
      "Epoch 23/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5593 - binary_crossentropy: 0.0677\n",
      "Epoch 00023: val_loss improved from 1.57226 to 1.57085, saving model to ./ckpt/my_checkpoint/KM-0023.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0023.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5592 - binary_crossentropy: 0.0677 - val_loss: 1.5708 - val_binary_crossentropy: 0.0668\n",
      "Epoch 24/500\n",
      "4395/4408 [============================>.] - ETA: 0s - loss: 1.5581 - binary_crossentropy: 0.0678\n",
      "Epoch 00024: val_loss improved from 1.57085 to 1.57030, saving model to ./ckpt/my_checkpoint/KM-0024.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0024.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 4ms/step - loss: 1.5582 - binary_crossentropy: 0.0678 - val_loss: 1.5703 - val_binary_crossentropy: 0.0663\n",
      "Epoch 25/500\n",
      "4401/4408 [============================>.] - ETA: 0s - loss: 1.5571 - binary_crossentropy: 0.0678\n",
      "Epoch 00025: val_loss improved from 1.57030 to 1.56903, saving model to ./ckpt/my_checkpoint/KM-0025.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0025.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5571 - binary_crossentropy: 0.0678 - val_loss: 1.5690 - val_binary_crossentropy: 0.0664\n",
      "Epoch 26/500\n",
      "4395/4408 [============================>.] - ETA: 0s - loss: 1.5563 - binary_crossentropy: 0.0678\n",
      "Epoch 00026: val_loss did not improve from 1.56903\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5563 - binary_crossentropy: 0.0678 - val_loss: 1.5691 - val_binary_crossentropy: 0.0664\n",
      "Epoch 27/500\n",
      "4401/4408 [============================>.] - ETA: 0s - loss: 1.5553 - binary_crossentropy: 0.0678\n",
      "Epoch 00027: val_loss improved from 1.56903 to 1.56800, saving model to ./ckpt/my_checkpoint/KM-0027.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0027.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5553 - binary_crossentropy: 0.0678 - val_loss: 1.5680 - val_binary_crossentropy: 0.0666\n",
      "Epoch 28/500\n",
      "4401/4408 [============================>.] - ETA: 0s - loss: 1.5546 - binary_crossentropy: 0.0677\n",
      "Epoch 00028: val_loss improved from 1.56800 to 1.56695, saving model to ./ckpt/my_checkpoint/KM-0028.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0028.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5546 - binary_crossentropy: 0.0677 - val_loss: 1.5669 - val_binary_crossentropy: 0.0665\n",
      "Epoch 29/500\n",
      "4393/4408 [============================>.] - ETA: 0s - loss: 1.5537 - binary_crossentropy: 0.0678\n",
      "Epoch 00029: val_loss improved from 1.56695 to 1.56677, saving model to ./ckpt/my_checkpoint/KM-0029.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0029.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5536 - binary_crossentropy: 0.0678 - val_loss: 1.5668 - val_binary_crossentropy: 0.0666\n",
      "Epoch 30/500\n",
      "4394/4408 [============================>.] - ETA: 0s - loss: 1.5534 - binary_crossentropy: 0.0678\n",
      "Epoch 00030: val_loss improved from 1.56677 to 1.56632, saving model to ./ckpt/my_checkpoint/KM-0030.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0030.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5533 - binary_crossentropy: 0.0678 - val_loss: 1.5663 - val_binary_crossentropy: 0.0665\n",
      "Epoch 31/500\n",
      "4395/4408 [============================>.] - ETA: 0s - loss: 1.5527 - binary_crossentropy: 0.0678\n",
      "Epoch 00031: val_loss improved from 1.56632 to 1.56585, saving model to ./ckpt/my_checkpoint/KM-0031.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0031.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5527 - binary_crossentropy: 0.0678 - val_loss: 1.5659 - val_binary_crossentropy: 0.0668\n",
      "Epoch 32/500\n",
      "4395/4408 [============================>.] - ETA: 0s - loss: 1.5522 - binary_crossentropy: 0.0678\n",
      "Epoch 00032: val_loss improved from 1.56585 to 1.56473, saving model to ./ckpt/my_checkpoint/KM-0032.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0032.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5523 - binary_crossentropy: 0.0678 - val_loss: 1.5647 - val_binary_crossentropy: 0.0668\n",
      "Epoch 33/500\n",
      "4406/4408 [============================>.] - ETA: 0s - loss: 1.5517 - binary_crossentropy: 0.0678\n",
      "Epoch 00033: val_loss did not improve from 1.56473\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5517 - binary_crossentropy: 0.0678 - val_loss: 1.5653 - val_binary_crossentropy: 0.0664\n",
      "Epoch 34/500\n",
      "4397/4408 [============================>.] - ETA: 0s - loss: 1.5514 - binary_crossentropy: 0.0678\n",
      "Epoch 00034: val_loss did not improve from 1.56473\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5514 - binary_crossentropy: 0.0678 - val_loss: 1.5651 - val_binary_crossentropy: 0.0663\n",
      "Epoch 35/500\n",
      "4407/4408 [============================>.] - ETA: 0s - loss: 1.5510 - binary_crossentropy: 0.0678\n",
      "Epoch 00035: val_loss did not improve from 1.56473\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5510 - binary_crossentropy: 0.0678 - val_loss: 1.5648 - val_binary_crossentropy: 0.0664\n",
      "Epoch 36/500\n",
      "4397/4408 [============================>.] - ETA: 0s - loss: 1.5505 - binary_crossentropy: 0.0678\n",
      "Epoch 00036: val_loss did not improve from 1.56473\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5505 - binary_crossentropy: 0.0678 - val_loss: 1.5647 - val_binary_crossentropy: 0.0666\n",
      "Epoch 37/500\n",
      "4407/4408 [============================>.] - ETA: 0s - loss: 1.5504 - binary_crossentropy: 0.0678\n",
      "Epoch 00037: val_loss improved from 1.56473 to 1.56399, saving model to ./ckpt/my_checkpoint/KM-0037.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0037.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5505 - binary_crossentropy: 0.0678 - val_loss: 1.5640 - val_binary_crossentropy: 0.0666\n",
      "Epoch 38/500\n",
      "4400/4408 [============================>.] - ETA: 0s - loss: 1.5503 - binary_crossentropy: 0.0678\n",
      "Epoch 00038: val_loss improved from 1.56399 to 1.56383, saving model to ./ckpt/my_checkpoint/KM-0038.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0038.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5503 - binary_crossentropy: 0.0678 - val_loss: 1.5638 - val_binary_crossentropy: 0.0667\n",
      "Epoch 39/500\n",
      "4394/4408 [============================>.] - ETA: 0s - loss: 1.5498 - binary_crossentropy: 0.0678\n",
      "Epoch 00039: val_loss improved from 1.56383 to 1.56352, saving model to ./ckpt/my_checkpoint/KM-0039.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0039.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5498 - binary_crossentropy: 0.0678 - val_loss: 1.5635 - val_binary_crossentropy: 0.0668\n",
      "Epoch 40/500\n",
      "4391/4408 [============================>.] - ETA: 0s - loss: 1.5500 - binary_crossentropy: 0.0678\n",
      "Epoch 00040: val_loss did not improve from 1.56352\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5501 - binary_crossentropy: 0.0678 - val_loss: 1.5638 - val_binary_crossentropy: 0.0668\n",
      "Epoch 41/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5494 - binary_crossentropy: 0.0678\n",
      "Epoch 00041: val_loss did not improve from 1.56352\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5493 - binary_crossentropy: 0.0678 - val_loss: 1.5637 - val_binary_crossentropy: 0.0666\n",
      "Epoch 42/500\n",
      "4403/4408 [============================>.] - ETA: 0s - loss: 1.5497 - binary_crossentropy: 0.0678\n",
      "Epoch 00042: val_loss improved from 1.56352 to 1.56337, saving model to ./ckpt/my_checkpoint/KM-0042.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0042.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5497 - binary_crossentropy: 0.0678 - val_loss: 1.5634 - val_binary_crossentropy: 0.0665\n",
      "Epoch 43/500\n",
      "4402/4408 [============================>.] - ETA: 0s - loss: 1.5497 - binary_crossentropy: 0.0678\n",
      "Epoch 00043: val_loss did not improve from 1.56337\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5497 - binary_crossentropy: 0.0678 - val_loss: 1.5636 - val_binary_crossentropy: 0.0665\n",
      "Epoch 44/500\n",
      "4398/4408 [============================>.] - ETA: 0s - loss: 1.5494 - binary_crossentropy: 0.0678\n",
      "Epoch 00044: val_loss improved from 1.56337 to 1.56279, saving model to ./ckpt/my_checkpoint/KM-0044.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0044.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5494 - binary_crossentropy: 0.0678 - val_loss: 1.5628 - val_binary_crossentropy: 0.0667\n",
      "Epoch 45/500\n",
      "4393/4408 [============================>.] - ETA: 0s - loss: 1.5493 - binary_crossentropy: 0.0678\n",
      "Epoch 00045: val_loss improved from 1.56279 to 1.56256, saving model to ./ckpt/my_checkpoint/KM-0045.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0045.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5492 - binary_crossentropy: 0.0678 - val_loss: 1.5626 - val_binary_crossentropy: 0.0665\n",
      "Epoch 46/500\n",
      "4401/4408 [============================>.] - ETA: 0s - loss: 1.5492 - binary_crossentropy: 0.0678\n",
      "Epoch 00046: val_loss did not improve from 1.56256\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5492 - binary_crossentropy: 0.0678 - val_loss: 1.5626 - val_binary_crossentropy: 0.0666\n",
      "Epoch 47/500\n",
      "4403/4408 [============================>.] - ETA: 0s - loss: 1.5489 - binary_crossentropy: 0.0678\n",
      "Epoch 00047: val_loss improved from 1.56256 to 1.56256, saving model to ./ckpt/my_checkpoint/KM-0047.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0047.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5489 - binary_crossentropy: 0.0678 - val_loss: 1.5626 - val_binary_crossentropy: 0.0666\n",
      "Epoch 48/500\n",
      "4391/4408 [============================>.] - ETA: 0s - loss: 1.5489 - binary_crossentropy: 0.0678\n",
      "Epoch 00048: val_loss did not improve from 1.56256\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5490 - binary_crossentropy: 0.0678 - val_loss: 1.5631 - val_binary_crossentropy: 0.0664\n",
      "Epoch 49/500\n",
      "4397/4408 [============================>.] - ETA: 0s - loss: 1.5490 - binary_crossentropy: 0.0678\n",
      "Epoch 00049: val_loss improved from 1.56256 to 1.56231, saving model to ./ckpt/my_checkpoint/KM-0049.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0049.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5490 - binary_crossentropy: 0.0678 - val_loss: 1.5623 - val_binary_crossentropy: 0.0666\n",
      "Epoch 50/500\n",
      "4399/4408 [============================>.] - ETA: 0s - loss: 1.5491 - binary_crossentropy: 0.0678\n",
      "Epoch 00050: val_loss did not improve from 1.56231\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5491 - binary_crossentropy: 0.0678 - val_loss: 1.5630 - val_binary_crossentropy: 0.0666\n",
      "Epoch 51/500\n",
      "4407/4408 [============================>.] - ETA: 0s - loss: 1.5488 - binary_crossentropy: 0.0678\n",
      "Epoch 00051: val_loss did not improve from 1.56231\n",
      "4408/4408 [==============================] - 12s 3ms/step - loss: 1.5488 - binary_crossentropy: 0.0678 - val_loss: 1.5624 - val_binary_crossentropy: 0.0669\n",
      "Epoch 52/500\n",
      "4406/4408 [============================>.] - ETA: 0s - loss: 1.5484 - binary_crossentropy: 0.0678\n",
      "Epoch 00052: val_loss did not improve from 1.56231\n",
      "4408/4408 [==============================] - 12s 3ms/step - loss: 1.5484 - binary_crossentropy: 0.0678 - val_loss: 1.5629 - val_binary_crossentropy: 0.0662\n",
      "Epoch 53/500\n",
      "4401/4408 [============================>.] - ETA: 0s - loss: 1.5486 - binary_crossentropy: 0.0678\n",
      "Epoch 00053: val_loss improved from 1.56231 to 1.56206, saving model to ./ckpt/my_checkpoint/KM-0053.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0053.ckpt/assets\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5486 - binary_crossentropy: 0.0678 - val_loss: 1.5621 - val_binary_crossentropy: 0.0665\n",
      "Epoch 54/500\n",
      "4400/4408 [============================>.] - ETA: 0s - loss: 1.5484 - binary_crossentropy: 0.0678\n",
      "Epoch 00054: val_loss did not improve from 1.56206\n",
      "4408/4408 [==============================] - 12s 3ms/step - loss: 1.5485 - binary_crossentropy: 0.0678 - val_loss: 1.5628 - val_binary_crossentropy: 0.0667\n",
      "Epoch 55/500\n",
      "4396/4408 [============================>.] - ETA: 0s - loss: 1.5489 - binary_crossentropy: 0.0678\n",
      "Epoch 00055: val_loss did not improve from 1.56206\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5489 - binary_crossentropy: 0.0678 - val_loss: 1.5623 - val_binary_crossentropy: 0.0667\n",
      "Epoch 56/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5485 - binary_crossentropy: 0.0678\n",
      "Epoch 00056: val_loss improved from 1.56206 to 1.56201, saving model to ./ckpt/my_checkpoint/KM-0056.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0056.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5485 - binary_crossentropy: 0.0678 - val_loss: 1.5620 - val_binary_crossentropy: 0.0666\n",
      "Epoch 57/500\n",
      "4395/4408 [============================>.] - ETA: 0s - loss: 1.5485 - binary_crossentropy: 0.0678\n",
      "Epoch 00057: val_loss did not improve from 1.56201\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5485 - binary_crossentropy: 0.0678 - val_loss: 1.5622 - val_binary_crossentropy: 0.0669\n",
      "Epoch 58/500\n",
      "4405/4408 [============================>.] - ETA: 0s - loss: 1.5486 - binary_crossentropy: 0.0678\n",
      "Epoch 00058: val_loss did not improve from 1.56201\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5486 - binary_crossentropy: 0.0678 - val_loss: 1.5627 - val_binary_crossentropy: 0.0663\n",
      "Epoch 59/500\n",
      "4399/4408 [============================>.] - ETA: 0s - loss: 1.5484 - binary_crossentropy: 0.0678\n",
      "Epoch 00059: val_loss did not improve from 1.56201\n",
      "4408/4408 [==============================] - 12s 3ms/step - loss: 1.5484 - binary_crossentropy: 0.0678 - val_loss: 1.5624 - val_binary_crossentropy: 0.0666\n",
      "Epoch 60/500\n",
      "4393/4408 [============================>.] - ETA: 0s - loss: 1.5488 - binary_crossentropy: 0.0678\n",
      "Epoch 00060: val_loss did not improve from 1.56201\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5488 - binary_crossentropy: 0.0678 - val_loss: 1.5624 - val_binary_crossentropy: 0.0665\n",
      "Epoch 61/500\n",
      "4397/4408 [============================>.] - ETA: 0s - loss: 1.5484 - binary_crossentropy: 0.0678\n",
      "Epoch 00061: val_loss did not improve from 1.56201\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5484 - binary_crossentropy: 0.0678 - val_loss: 1.5623 - val_binary_crossentropy: 0.0667\n",
      "Epoch 62/500\n",
      "4390/4408 [============================>.] - ETA: 0s - loss: 1.5489 - binary_crossentropy: 0.0678\n",
      "Epoch 00062: val_loss did not improve from 1.56201\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5489 - binary_crossentropy: 0.0678 - val_loss: 1.5632 - val_binary_crossentropy: 0.0667\n",
      "Epoch 63/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5485 - binary_crossentropy: 0.0678\n",
      "Epoch 00063: val_loss did not improve from 1.56201\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5485 - binary_crossentropy: 0.0678 - val_loss: 1.5629 - val_binary_crossentropy: 0.0662\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(input_data, train_y, \n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size, \n",
    "                  validation_data=(val_data, val_y), \n",
    "                  callbacks=[lr_sched, Early, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/widendeep_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./model/widendeep_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2e72c8d950>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train input data와 같은 방식으로 test data를 input 형식에 맞추어줌\n",
    "eval_input_data = [test_x_continue] + [test_x_category[:, i] for i in range(test_x_category.shape[1])] + [test_x_category_poly] + [test_x_embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031/1031 [==============================] - 1s 1ms/step - loss: 1.5628 - binary_crossentropy: 0.0663\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(eval_input_data, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model.predict(eval_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = data.loc[test_x.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot에서 같은 trans_id는 더해줌.\n",
    "receipt_y = test_y.copy()\n",
    "receipt_y['trans_id'] = test_x['trans_id']\n",
    "frame = pd.DataFrame(data = receipt_y['trans_id'], columns=['trans_id'])\n",
    "receipt_y = receipt_y.groupby('trans_id', as_index=False).sum()\n",
    "receipt_y = frame.merge(receipt_y, how='left').set_index(test_x.index)\n",
    "receipt_y.drop('trans_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chilled Snacks</th>\n",
       "      <th>Snacks</th>\n",
       "      <th>Hot Snacks</th>\n",
       "      <th>Women's Upper Bodywear / Tops</th>\n",
       "      <th>Chilled Instant Foods</th>\n",
       "      <th>Bakery</th>\n",
       "      <th>Lighting Accessories</th>\n",
       "      <th>Biscuits</th>\n",
       "      <th>Ham and Sausages</th>\n",
       "      <th>Fish Cakes and Crab Sticks</th>\n",
       "      <th>...</th>\n",
       "      <th>Soccer / Footbal</th>\n",
       "      <th>Sea Food Gift Sets</th>\n",
       "      <th>Writing Supplies</th>\n",
       "      <th>Business Paper Products</th>\n",
       "      <th>Car Accessories</th>\n",
       "      <th>Grain Gift Sets</th>\n",
       "      <th>Car Wash Equipment</th>\n",
       "      <th>Vegetable Gift Sets</th>\n",
       "      <th>Improvement Supplies</th>\n",
       "      <th>Safety Equipment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>626819</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626820</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626821</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626822</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626823</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Chilled Snacks  Snacks  Hot Snacks  Women's Upper Bodywear / Tops  \\\n",
       "626819             NaN     NaN         NaN                            NaN   \n",
       "626820             NaN     NaN         NaN                            NaN   \n",
       "626821             NaN     NaN         NaN                            NaN   \n",
       "626822             0.0     0.0         0.0                            0.0   \n",
       "626823             NaN     NaN         NaN                            NaN   \n",
       "\n",
       "        Chilled Instant Foods  Bakery  Lighting Accessories  Biscuits  \\\n",
       "626819                    NaN     NaN                   NaN       NaN   \n",
       "626820                    NaN     NaN                   NaN       NaN   \n",
       "626821                    NaN     NaN                   NaN       NaN   \n",
       "626822                    0.0     0.0                   0.0       0.0   \n",
       "626823                    NaN     NaN                   NaN       NaN   \n",
       "\n",
       "        Ham and Sausages  Fish Cakes and Crab Sticks  ...  Soccer / Footbal  \\\n",
       "626819               NaN                         NaN  ...               NaN   \n",
       "626820               NaN                         NaN  ...               NaN   \n",
       "626821               NaN                         NaN  ...               NaN   \n",
       "626822               0.0                         0.0  ...               0.0   \n",
       "626823               NaN                         NaN  ...               NaN   \n",
       "\n",
       "        Sea Food Gift Sets  Writing Supplies  Business Paper Products  \\\n",
       "626819                 NaN               NaN                      NaN   \n",
       "626820                 NaN               NaN                      NaN   \n",
       "626821                 NaN               NaN                      NaN   \n",
       "626822                 0.0               0.0                      0.0   \n",
       "626823                 NaN               NaN                      NaN   \n",
       "\n",
       "        Car Accessories  Grain Gift Sets  Car Wash Equipment  \\\n",
       "626819              NaN              NaN                 NaN   \n",
       "626820              NaN              NaN                 NaN   \n",
       "626821              NaN              NaN                 NaN   \n",
       "626822              0.0              0.0                 0.0   \n",
       "626823              NaN              NaN                 NaN   \n",
       "\n",
       "        Vegetable Gift Sets  Improvement Supplies  Safety Equipment  \n",
       "626819                  NaN                   NaN               NaN  \n",
       "626820                  NaN                   NaN               NaN  \n",
       "626821                  NaN                   NaN               NaN  \n",
       "626822                  0.0                   0.0               0.0  \n",
       "626823                  NaN                   NaN               NaN  \n",
       "\n",
       "[5 rows x 309 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receipt_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 영수증 별로 구매 아이템을 묶어주는 작업.\n",
    "test_label = data.loc[test_x.index][['clnt_id','sess_id', 'clac_nm2']]\n",
    "frame = pd.DataFrame(data = test_label[['clnt_id','sess_id']], columns=['clnt_id', 'sess_id'])\n",
    "test_label = test_label.groupby(['clnt_id','sess_id'])['clac_nm2'].apply(lambda x: ', '.join(x))\n",
    "test_label = frame.merge(test_label, on=['clnt_id', 'sess_id'],how='left').set_index(test_x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>sess_id</th>\n",
       "      <th>clac_nm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>626832</th>\n",
       "      <td>31350</td>\n",
       "      <td>91</td>\n",
       "      <td>Women's Lower Bodywear / Bottoms, Women's Lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626833</th>\n",
       "      <td>37794</td>\n",
       "      <td>114</td>\n",
       "      <td>Traditional Rice Cakes, Hot Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626834</th>\n",
       "      <td>37794</td>\n",
       "      <td>114</td>\n",
       "      <td>Traditional Rice Cakes, Hot Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626835</th>\n",
       "      <td>54771</td>\n",
       "      <td>40</td>\n",
       "      <td>Fish Cakes and Crab Sticks, Girl's Toys, Chill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626836</th>\n",
       "      <td>54771</td>\n",
       "      <td>40</td>\n",
       "      <td>Fish Cakes and Crab Sticks, Girl's Toys, Chill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        clnt_id  sess_id                                           clac_nm2\n",
       "626832    31350       91  Women's Lower Bodywear / Bottoms, Women's Lowe...\n",
       "626833    37794      114                 Traditional Rice Cakes, Hot Snacks\n",
       "626834    37794      114                 Traditional Rice Cakes, Hot Snacks\n",
       "626835    54771       40  Fish Cakes and Crab Sticks, Girl's Toys, Chill...\n",
       "626836    54771       40  Fish Cakes and Crab Sticks, Girl's Toys, Chill..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.head(18).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pd = pd.DataFrame(prob, columns=receipt_y.columns)\n",
    "cond = list(np.sum(receipt_y.values, axis=1) > 10)\n",
    "cond_pd = score_pd[cond].reset_index(drop= True)\n",
    "test_pd = test_label[cond].reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "pred_matrix: 예측된 아이템 행렬 파라미터.\n",
    "top_n: 상위 몇개를 추천으로 사용할 지 정하는 파라미터.\n",
    "test_matix: 고객ID와 Target이 있는 행렬 파라미터\n",
    "'''\n",
    "def get_acc(score_matrix, top_n, test_matix):\n",
    "    avg_acc = 0\n",
    "    match_list = []\n",
    "    for i in range(len(score_matrix)):\n",
    "        top = score_matrix.iloc[i].nlargest(top_n).index\n",
    "        tmp = 0\n",
    "        match = np.zeros(top_n).astype(np.int8).tolist()\n",
    "        for j in range(len(top)):\n",
    "            true_buy = [k for k in test_matix[\"clac_nm2\"][i].split(', ')]\n",
    "            if top[j] in true_buy :\n",
    "                tmp += 1\n",
    "                match[j] = 1\n",
    "        match_list.append(match)\n",
    "        acc = tmp / len(top)\n",
    "        avg_acc += acc / len(score_matrix)\n",
    "    print(\"Accuracy of Top {}: {:>.3f}%\\n\".format(top_n, avg_acc*100))\n",
    "    return avg_acc, match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(r, k):\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k] != 0\n",
    "    if r.size != k:\n",
    "        raise ValueError('Relevance score length < k')\n",
    "    return np.mean(r)\n",
    "\n",
    "\n",
    "def average_precision(r):\n",
    "    r = np.asarray(r) != 0\n",
    "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
    "    if not out:\n",
    "        return 0.\n",
    "    return np.mean(out)\n",
    "    \n",
    "def mean_average_precision(rs):\n",
    "    return np.mean([average_precision(r) for r in rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Top 5: 7.573%\n",
      "\n",
      "MAP: 16.6%\n"
     ]
    }
   ],
   "source": [
    "accuracy, match_list =  get_acc(cond_pd, 5 , test_pd) \n",
    "map_val = mean_average_precision(match_list)\n",
    "print(\"MAP: {:.3}%\".format(map_val*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_list(predict_y, top_n, target_matrix):\n",
    "    test_matrix = target_matrix.copy()\n",
    "    pred_matrix = predict_y.copy()\n",
    "    for i in range(len(pred_matrix)):\n",
    "        top = pred_matrix.iloc[i].nlargest(top_n).index\n",
    "        top = pd.DataFrame(top.astype(str).to_frame().apply(lambda x: \", \".join(x)))\n",
    "        test_matrix.loc[i, 'pred'] = top.values[0]\n",
    "    return test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'word': clac_nm2, 'label': data['clac_nm2']}\n",
    "df = pd.DataFrame(data=d).drop_duplicates()\n",
    "cate2papago = df.set_index('label').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_pred_list(cond_pd, 10, test_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.groupby('sess_id', as_index=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_item(test, column_name):\n",
    "    item_list = []\n",
    "    for i in range(test.shape[0]):\n",
    "        tmp_list = []\n",
    "        for a in test.iloc[i][column_name].split(', '):\n",
    "            tmp_list.append(a)\n",
    "        item_list.append(tmp_list)\n",
    "    return item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_id</th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>clac_nm2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7090</td>\n",
       "      <td>Instant Noodles, Dried Noodles, Dried Noodles,...</td>\n",
       "      <td>Hand / Foot Care, Mushrooms, Travel Bags, Frui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63998</td>\n",
       "      <td>Chilled Instant Foods, Lighting Accessories, F...</td>\n",
       "      <td>Fruit Vegetables, Leaf Vegetables, Travel Bags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60449</td>\n",
       "      <td>Packaged Side Dishes, Bakery, Hot Snacks, Seas...</td>\n",
       "      <td>Hand / Foot Care, Travel Bags, Fitness Trainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30297</td>\n",
       "      <td>Eggs, Processed Seaweeds, Processed Seaweeds, ...</td>\n",
       "      <td>Fruit Vegetables, Hand / Foot Care, Traditiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>24029</td>\n",
       "      <td>Chilled Snacks, Chilled Snacks, Bakery, Chille...</td>\n",
       "      <td>Fitness Training, Leaf Vegetables, Hand / Foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>130</td>\n",
       "      <td>45092</td>\n",
       "      <td>Ham and Sausages, Chilled Snacks, Ham and Saus...</td>\n",
       "      <td>Hand / Foot Care, Girls' Outwear, Fruit Vegeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>134</td>\n",
       "      <td>15518</td>\n",
       "      <td>Biscuits, Processed Milk, Frozen Instant Foods...</td>\n",
       "      <td>Safety Equipment, Hand / Foot Care, Fruit Vege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>138</td>\n",
       "      <td>35673</td>\n",
       "      <td>Mushrooms, Yogurt, Biscuits, Frozen Instant Fo...</td>\n",
       "      <td>Fruit Vegetables, Kids' Underwear, Leaf Vegeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>196</td>\n",
       "      <td>62232</td>\n",
       "      <td>Leaf Vegetables, Frozen Instant Foods, Tissues...</td>\n",
       "      <td>Fruit Vegetables, Girls' Outwear, Hand / Foot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>257</td>\n",
       "      <td>23121</td>\n",
       "      <td>Hot Snacks, Chilled Snacks, Snacks, Chocolates...</td>\n",
       "      <td>Hand / Foot Care, Traditional Rice Cakes, Frui...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sess_id  clnt_id                                           clac_nm2  \\\n",
       "0         1     7090  Instant Noodles, Dried Noodles, Dried Noodles,...   \n",
       "1         2    63998  Chilled Instant Foods, Lighting Accessories, F...   \n",
       "2         3    60449  Packaged Side Dishes, Bakery, Hot Snacks, Seas...   \n",
       "3         4    30297  Eggs, Processed Seaweeds, Processed Seaweeds, ...   \n",
       "4         5    24029  Chilled Snacks, Chilled Snacks, Bakery, Chille...   \n",
       "..      ...      ...                                                ...   \n",
       "75      130    45092  Ham and Sausages, Chilled Snacks, Ham and Saus...   \n",
       "76      134    15518  Biscuits, Processed Milk, Frozen Instant Foods...   \n",
       "77      138    35673  Mushrooms, Yogurt, Biscuits, Frozen Instant Fo...   \n",
       "78      196    62232  Leaf Vegetables, Frozen Instant Foods, Tissues...   \n",
       "79      257    23121  Hot Snacks, Chilled Snacks, Snacks, Chocolates...   \n",
       "\n",
       "                                                 pred  \n",
       "0   Hand / Foot Care, Mushrooms, Travel Bags, Frui...  \n",
       "1   Fruit Vegetables, Leaf Vegetables, Travel Bags...  \n",
       "2   Hand / Foot Care, Travel Bags, Fitness Trainin...  \n",
       "3   Fruit Vegetables, Hand / Foot Care, Traditiona...  \n",
       "4   Fitness Training, Leaf Vegetables, Hand / Foot...  \n",
       "..                                                ...  \n",
       "75  Hand / Foot Care, Girls' Outwear, Fruit Vegeta...  \n",
       "76  Safety Equipment, Hand / Foot Care, Fruit Vege...  \n",
       "77  Fruit Vegetables, Kids' Underwear, Leaf Vegeta...  \n",
       "78  Fruit Vegetables, Girls' Outwear, Hand / Foot ...  \n",
       "79  Hand / Foot Care, Traditional Rice Cakes, Frui...  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dup(li):\n",
    "        my_set = set()\n",
    "        res = []\n",
    "        for e in li:\n",
    "            if e not in my_set:\n",
    "                res.append(e)\n",
    "                my_set.add(e)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(score_matrix, top_n, test_matix):\n",
    "    avg_acc = 0\n",
    "    match_list = []\n",
    "    for i in range(len(score_matrix)):\n",
    "        top = score_matrix.iloc[i].nlargest(top_n).index\n",
    "        tmp = 0\n",
    "        match = np.zeros(top_n).astype(np.int8).tolist()\n",
    "        for j in range(len(top)):\n",
    "            true_buy = [k.split(\", \")[0] for k in test_matix[\"clac_nm2\"][i].split()]\n",
    "            if top[j] in true_buy :\n",
    "                tmp += 1\n",
    "                match[j] = 1\n",
    "        match_list.append(match)\n",
    "        acc = tmp / len(top)\n",
    "        avg_acc += acc / len(score_matrix)\n",
    "    print(\"Hit rate of Top {}: {:>.5f}\".format(top_n, avg_acc))\n",
    "    return avg_acc, match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_with_table(a, b, index):\n",
    "    buy_list = remove_dup(a[index])\n",
    "    rec_list = remove_dup(b[index])\n",
    "    tmp=[]\n",
    "    match = np.zeros(len(b[index])).astype(np.int8).tolist()\n",
    "    for j in range(len(rec_list)):\n",
    "        if rec_list[j] in buy_list :\n",
    "            tmp.append(rec_list[j])\n",
    "            match[j] = 1\n",
    "    df1 = pd.DataFrame({\"They buy\": buy_list})\n",
    "    df2 = pd.DataFrame({\"We recommend\" : rec_list})\n",
    "    df = pd.concat([df1, df2], axis=1, sort=False)\n",
    "    \n",
    "    print(index, \"번째 로그 데이터에 대한 결과\\n\")\n",
    "    display(df)\n",
    "    for t, i in enumerate(tmp):\n",
    "        print(\"{}번째 추천 적중 상품 - {}\".format(t, i))\n",
    "    print(\"\\nAP:\", average_precision(match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_good_case(a, b, criteria=0.5):\n",
    "    good_map=[]\n",
    "    for index in range(len(a)):\n",
    "        buy_list = remove_dup(a[index])\n",
    "        rec_list = remove_dup(b[index])\n",
    "        match = np.zeros(len(b[index])).astype(np.int8).tolist()\n",
    "        for j in range(len(rec_list)):\n",
    "            if rec_list[j] in buy_list :\n",
    "                match[j] = 1\n",
    "        good_map.append(average_precision(match))\n",
    "    best_idx = []\n",
    "    for idx, v in enumerate(good_map):\n",
    "        if v >= criteria:\n",
    "            best_idx.append(idx)\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = id_to_item(test, 'clac_nm2')\n",
    "b = id_to_item(test, 'pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_case_idx = find_good_case(a, b, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 번째 로그 데이터에 대한 결과\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>They buy</th>\n",
       "      <th>We recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Books</td>\n",
       "      <td>Fruit Vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>Girls' Outwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musical Instruments</td>\n",
       "      <td>Hand / Foot Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yogurt</td>\n",
       "      <td>Skis / Snowboards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Domestic Fruits</td>\n",
       "      <td>Travel Bags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fruit Vegetables</td>\n",
       "      <td>Leaf Vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Leaf Vegetables</td>\n",
       "      <td>Kids' Tableware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mushrooms</td>\n",
       "      <td>Women's General Sport Clothing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Domestic Porks</td>\n",
       "      <td>Fruit and Vegetable Drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Dessert</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              They buy                    We recommend\n",
       "0                Books                Fruit Vegetables\n",
       "1               Snacks                  Girls' Outwear\n",
       "2  Musical Instruments                Hand / Foot Care\n",
       "3               Yogurt               Skis / Snowboards\n",
       "4      Domestic Fruits                     Travel Bags\n",
       "5     Fruit Vegetables                 Leaf Vegetables\n",
       "6      Leaf Vegetables                 Kids' Tableware\n",
       "7            Mushrooms  Women's General Sport Clothing\n",
       "8       Domestic Porks      Fruit and Vegetable Drinks\n",
       "9                  NaN                         Dessert"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 추천 적중 상품 - Fruit Vegetables\n",
      "1번째 추천 적중 상품 - Leaf Vegetables\n",
      "\n",
      "AP: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "show_with_table(a,b, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Entropy Diversity \n",
    "- 추천 결과가 얼마나 분산 되어 있느냐를 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "ideal = 'abcde'\n",
    "probid = [ float(ideal.count(c)) / len(ideal) for c in dict.fromkeys(list(ideal))]\n",
    "entropy_ideal = - sum([ p * math.log(p) / math.log(2.0) for p in probid ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6094379124341005"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_ideal = - sum([ p * math.log(p) for p in probid])\n",
    "entropy_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_diversity(li):\n",
    "    total = []\n",
    "    for first_list in li:\n",
    "        for items in first_list:\n",
    "            total.append(items)\n",
    "    total_unique = list(set(total))\n",
    "    probid = [ float(total.count(c)) / len(total) for c in total_unique]\n",
    "    entropy_ideal = - sum([ p * math.log(p) for p in probid])\n",
    "    return entropy_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6985442459601057"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_diversity(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
