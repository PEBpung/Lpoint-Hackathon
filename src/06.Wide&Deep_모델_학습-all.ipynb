{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wide & Deep Learning model 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "저희는 추천 시스템을 적용하기 위해서 `Wide & Deep` 모델을 사용했습니다. \n",
    "\n",
    "모델 구현에 대한 간단한 설명을 하겠습니다.  \n",
    "입력은 2개로 분리해서 생각하면 됩니다.  \n",
    "\n",
    "`Wide 모델`의 입력: category Feature을 `Polynomial`하게 바꿔준 데이터  \n",
    "`Deep 모델`의 입력: category Feature을 `embeding` 시켜준 데이터 + `continuous`한 데이터   \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3147: DtypeWarning: Columns (37) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>sess_id</th>\n",
       "      <th>hit_seq</th>\n",
       "      <th>action_type</th>\n",
       "      <th>biz_unit</th>\n",
       "      <th>sess_dt</th>\n",
       "      <th>hit_tm</th>\n",
       "      <th>hit_pss_tm</th>\n",
       "      <th>trans_id</th>\n",
       "      <th>sech_kwd</th>\n",
       "      <th>...</th>\n",
       "      <th>de_dt</th>\n",
       "      <th>de_tm</th>\n",
       "      <th>buy_am</th>\n",
       "      <th>buy_ct</th>\n",
       "      <th>clac_nm1</th>\n",
       "      <th>clac_nm2</th>\n",
       "      <th>clac_nm3</th>\n",
       "      <th>clnt_gender</th>\n",
       "      <th>clnt_age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121082</th>\n",
       "      <td>3390</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A01</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>지고트</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>Women's Outwear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194580</th>\n",
       "      <td>5535</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>A03</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>6532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194581</th>\n",
       "      <td>5535</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A03</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>30494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>양파</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>Chilled Instant Foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194582</th>\n",
       "      <td>5535</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>A03</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>32370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>Chilled Beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194583</th>\n",
       "      <td>5535</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>A03</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>41637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>우엉</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>Snacks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        clnt_id  sess_id  hit_seq  action_type biz_unit     sess_dt hit_tm  \\\n",
       "121082     3390        1        1            0      A01  2019-07-01  00:00   \n",
       "194580     5535        1        1            5      A03  2019-07-01  00:00   \n",
       "194581     5535        1        2            0      A03  2019-07-01  00:00   \n",
       "194582     5535        1        3            3      A03  2019-07-01  00:00   \n",
       "194583     5535        1        4            0      A03  2019-07-01  00:00   \n",
       "\n",
       "        hit_pss_tm  trans_id sech_kwd  ...  de_dt  de_tm buy_am buy_ct  \\\n",
       "121082           0       NaN      지고트  ...    NaN    NaN    NaN    NaN   \n",
       "194580        6532       NaN      NaN  ...    NaN    NaN    NaN    NaN   \n",
       "194581       30494       NaN       양파  ...    NaN    NaN    NaN    NaN   \n",
       "194582       32370       NaN      NaN  ...    NaN    NaN    NaN    NaN   \n",
       "194583       41637       NaN       우엉  ...    NaN    NaN    NaN    NaN   \n",
       "\n",
       "        clac_nm1  clac_nm2  clac_nm3  clnt_gender  clnt_age  \\\n",
       "121082       NaN       NaN       NaN      unknown   unknown   \n",
       "194580       NaN       NaN       NaN            F        30   \n",
       "194581       NaN       NaN       NaN            F        30   \n",
       "194582       NaN       NaN       NaN            F        30   \n",
       "194583       NaN       NaN       NaN            F        30   \n",
       "\n",
       "                        label  \n",
       "121082        Women's Outwear  \n",
       "194580                    NaN  \n",
       "194581  Chilled Instant Foods  \n",
       "194582      Chilled Beverages  \n",
       "194583                 Snacks  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merge = pd.read_csv('./data/Total_Data_1.csv')\n",
    "df_merge = df_merge[['clnt_id', 'sess_id', 'hit_seq', 'action_type', 'biz_unit', 'sess_dt',\n",
    "       'hit_tm', 'hit_pss_tm', 'trans_id', 'sech_kwd', 'tot_pag_view_ct',\n",
    "       'tot_sess_hr_v', 'trfc_src', 'dvc_ctg_nm', 'cum_act_0', 'cum_act_1',\n",
    "       'cum_act_2', 'cum_act_3', 'cum_act_4', 'cum_act_5', 'cum_act_6','sech_clac_nm2',\n",
    "       'cum_act_7', 'day', 'holiday', 'hour', 'prefer_dvc_trfc', 'hum', 'temp',\n",
    "       'pty', 'r06', 'clac_nm2','clnt_gender', 'clnt_age']]\n",
    "\n",
    "df_merge = df_merge.sort_values(['sess_dt', 'hit_tm'])\n",
    "df_merge.loc[df_merge['clac_nm2'].isnull(),'clac_nm2'] = df_merge['sech_clac_nm2']\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## label이 있는 행 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구매 이력이 있는 행: 24.55 %\n"
     ]
    }
   ],
   "source": [
    "df_buyer = df_merge[(df_merge['action_type']==0)|(df_merge['action_type']==6)]\n",
    "print('구매 이력이 있는 행:', round(len(df_buyer['clac_nm2']) / len(df_merge['clac_nm2']) * 100, 2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User2Vec 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유저 임베딩 데이터 load\n",
    "user2vec = pd.read_csv('./data/user2vec100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buyer = df_buyer[df_buyer['clac_nm2'].notna()]\n",
    "df_buyer = df_buyer.merge(user2vec, on=['clnt_id', 'sess_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_buyer.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col=['clnt_id', 'sess_id', 'hit_seq', 'action_type', 'hit_tm', 'trans_id','sech_clac_nm2', 'sess_dt', 'sech_kwd']\n",
    "df_buyer = df_buyer.drop(drop_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <br><br>\n",
    "## label 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "lab_len = len(df_buyer['clac_nm2'].value_counts())\n",
    "label_key = df_buyer['clac_nm2'].value_counts().keys()\n",
    "\n",
    "df_buyer['clac_nm2'] = le.fit_transform(df_buyer['clac_nm2'])\n",
    "clac_nm2 = df_buyer['clac_nm2'].copy()\n",
    "df_buyer.drop(['clac_nm2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = []\n",
    "for i in range(100):\n",
    "    x_col.append('X_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_COLUMNS = [\n",
    "    'biz_unit', 'hit_pss_tm', 'tot_pag_view_ct', 'tot_sess_hr_v',  \n",
    "       'trfc_src', 'dvc_ctg_nm', 'cum_act_0', 'cum_act_1', 'cum_act_2',\n",
    "       'cum_act_3', 'cum_act_4', 'cum_act_5', 'cum_act_6', 'cum_act_7', 'day',\n",
    "       'holiday', 'hour', 'prefer_dvc_trfc', 'hum', 'temp', 'pty', 'r06',\n",
    "       'clnt_gender', 'clnt_age'\n",
    "]\n",
    "\n",
    "CATEGORICAL_COLUMNS = [\n",
    "    \"biz_unit\", 'trfc_src', 'dvc_ctg_nm',  \n",
    "    'prefer_dvc_trfc', 'clnt_gender', 'clnt_age', 'pty'\n",
    "]\n",
    "\n",
    "EMBEDDED_COLUMNS = x_col\n",
    "\n",
    "CONTINUOUS_COLUMNS = list(set(ALL_COLUMNS).difference(CATEGORICAL_COLUMNS+EMBEDDED_COLUMNS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_buyer.loc[df_buyer['clnt_gender'].isnull(),'clnt_gender'] = 'U'\n",
    "df_buyer.loc[df_buyer['clnt_age'].isnull(),'clnt_age'] =  -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in CATEGORICAL_COLUMNS:\n",
    "    le = LabelEncoder()\n",
    "    df_buyer[c] = le.fit_transform(df_buyer[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = clac_nm2.copy()\n",
    "label = np.eye(lab_len)[label]\n",
    "label = pd.DataFrame(data=label, columns=label_key, index=df_buyer.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Train 데이터, Test 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x , train_y , test_y = train_test_split(df_buyer , label , test_size=0.05, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터:  (626819, 124)\n",
      "Test 데이터:  (32991, 124)\n",
      "Train 라벨:  (626819, 309)\n",
      "Test 라벨:  (32991, 309)\n"
     ]
    }
   ],
   "source": [
    "print('Train 데이터: ', train_x.shape)\n",
    "print('Test 데이터: ', test_x.shape)\n",
    "print('Train 라벨: ', train_y.shape)\n",
    "print('Test 라벨: ', test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x , train_y , val_y = train_test_split(train_x , train_y , test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터:  (564137, 124)\n",
      "Val 데이터:  (62682, 124)\n",
      "Train 라벨:  (564137, 309)\n",
      "Val 라벨:  (62682, 309)\n"
     ]
    }
   ],
   "source": [
    "print('Train 데이터: ', train_x.shape)\n",
    "print('Val 데이터: ', val_x.shape)\n",
    "print('Train 라벨: ', train_y.shape)\n",
    "print('Val 라벨: ', val_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Column 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_category = np.array(train_x[CATEGORICAL_COLUMNS])\n",
    "test_x_category  = np.array(test_x[CATEGORICAL_COLUMNS])\n",
    "val_x_category   = np.array(val_x[CATEGORICAL_COLUMNS])\n",
    "\n",
    "train_x_embedding = np.array(train_x[EMBEDDED_COLUMNS])\n",
    "test_x_embedding  = np.array(test_x[EMBEDDED_COLUMNS])\n",
    "val_x_embedding   = np.array(val_x[EMBEDDED_COLUMNS])\n",
    "\n",
    "train_x_continue = np.array(train_x[CONTINUOUS_COLUMNS], dtype='float64')\n",
    "test_x_continue = np.array(test_x[CONTINUOUS_COLUMNS], dtype='float64')\n",
    "val_x_continue = np.array(val_x[CONTINUOUS_COLUMNS], dtype='float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_x_continue = scaler.fit_transform(train_x_continue)\n",
    "test_x_continue = scaler.transform(test_x_continue)\n",
    "val_x_continue = scaler.transform(val_x_continue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 정규화 내용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.605023918592604\n",
      "-11.354365361540133\n",
      "-11.324531784106053\n",
      "-11.312471934166016\n",
      "-11.302824361617713\n"
     ]
    }
   ],
   "source": [
    "print(train_x_continue[0].sum())\n",
    "print(train_x_continue[1].sum())\n",
    "print(train_x_continue[2].sum())\n",
    "print(train_x_continue[3].sum())\n",
    "print(train_x_continue[4].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Polynomial 적용\n",
    "    - 카테고리 값을 Polynomial로 바꿔줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* sklearn.preprocessing.PolynomialFeatures 메소드\n",
    "    - degree : 다항식 차수\n",
    "    - interaction_only\n",
    "        - default는 False\n",
    "        - ex) degree = 3일 때, interaction_only=false 이면\n",
    "            - a^2, a^3, b^2, b^3, ab, a^2*b, ab^2 Feature가 추가되고,\n",
    "        - interaction_only=True 이면\n",
    "            - ab만 추가됨\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_category_poly = poly.fit_transform(train_x_category)\n",
    "test_x_category_poly = poly.fit_transform(test_x_category)\n",
    "val_x_category_poly = poly.fit_transform(val_x_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564137, 29)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_category_poly.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구현에 대한 간단한 설명을 하겠습니다.  \n",
    "입력은 2개로 분리해서 생각하면 됩니다.  \n",
    "\n",
    "Wide 모델의 입력: category Feature을 Polynomial하게 바꿔준 데이터  \n",
    "Deep 모델의 입력: category Feature을 embeding 시켜준 데이터 + continuous한 데이터  \n",
    "\n",
    "그리고 출력은 lgbm 모델과 마찬가지로 1058개의 prediction 값이 row만큼 출력 됩니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.python.keras.layers.advanced_activations import ReLU, PReLU, LeakyReLU, ELU\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.keras.models import Model\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 0.9\n",
    "lr = 1e-5\n",
    "l1 = 0.01\n",
    "l2 = 0.01\n",
    "momentum = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deep_model():\n",
    "    \n",
    "    category_inputs = []\n",
    "    category_embeds = []\n",
    "    \n",
    "    # Categorical Data Embedding\n",
    "    for i in range(len(CATEGORICAL_COLUMNS)):\n",
    "        \n",
    "        # input - embedding - flatten 순으로 layer 쌓기\n",
    "        input_i = Input(shape=(1,), dtype='int32')\n",
    "        \n",
    "        dim = len(np.unique(df_buyer[CATEGORICAL_COLUMNS[i]]))\n",
    "        \n",
    "        embed_dim = int(np.ceil(dim ** 0.5))\n",
    "        \n",
    "        embed_i = Embedding(dim, embed_dim, input_length=1)(input_i)\n",
    "        # dim : 데이터가 몇 종류 있는지 = 임베딩 벡터를 몇 개 뽑아낼 것인지\n",
    "        # embed_dim : 임베딩 처리 후 벡터의 차원 = 임베딩 벡터를 몇 차원 벡터로 뽑아 낼 것인지\n",
    "        # input_length : 입력 데이터 길이\n",
    "        \n",
    "        flatten_i = Flatten()(embed_i)\n",
    "        # category 값을 임베딩환 벡터들을 flatten\n",
    "        \n",
    "        category_inputs.append(input_i)\n",
    "        category_embeds.append(flatten_i)\n",
    "        \n",
    "    # continuous 데이터 input\n",
    "    continue_input = Input(shape=(len(CONTINUOUS_COLUMNS),))\n",
    "    continue_dense = Dense(256, use_bias=False)(continue_input)\n",
    "    \n",
    "    # category와 continue를 합침\n",
    "    concat_embeds = concatenate([continue_dense] + category_embeds)\n",
    "    concat_embeds = Activation('relu')(concat_embeds)\n",
    "    \n",
    "    bn_concat = BatchNormalization(momentum=momentum)( concat_embeds)\n",
    "    \n",
    "    fc1 = Dense(512, use_bias=False)(bn_concat)\n",
    "    relu1 = ReLU()(fc1)\n",
    "    bn1 = BatchNormalization()(relu1)\n",
    "    fc2 = Dense(256, use_bias=False)(bn1)\n",
    "    relu2 = ReLU()(fc2)\n",
    "    bn2 = BatchNormalization()(relu2)\n",
    "    fc3 = Dense(128)(bn2)\n",
    "    deep = ReLU()(fc3)\n",
    "    \n",
    "    return category_inputs, continue_input, deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train_category_poly : 카테고리 데이터를 숫자로 바꾸고, Poly Feature를 추가한 것\n",
    "# Poly Feature : a, b, c Feature를 이용해서 ab, bc, ca Feature를 만든것\n",
    "# 데이터의 shape 만 가져옴\n",
    "def get_wide_model(poly):\n",
    "    dim = poly.shape[1]\n",
    "    return tf.keras.layers.Input(shape=(dim,))\n",
    "\n",
    "def get_embed_model(embed):\n",
    "    dim = embed.shape[1]\n",
    "    return tf.keras.layers.Input(shape=(dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input - embedding - flatten 순으로 layer 쌓기\n",
    "category_inputs, continue_input, deep_model = get_deep_model()\n",
    "wide_model = get_wide_model(train_x_category_poly)\n",
    "embed_model = get_embed_model(train_x_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### Wide모델과 Deep model을 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = concatenate([deep_model, wide_model, embed_model])\n",
    "inputs = [continue_input] + category_inputs + [wide_model] + [embed_model]\n",
    "output = Dense(len(label_key), activation='sigmoid')(concat)\n",
    "model = Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "### 입력 데이터\n",
    "\n",
    "    * 위에서 정의한 리스트 변수 inputs에 맞추어\n",
    "    * continue 데이터 => category 데이터 => poly data 순으로 입력 값을 넣어준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [train_x_continue] + [train_x_category[:, i] \\\n",
    "             for i in range(train_x_category.shape[1])] + \\\n",
    "             [train_x_category_poly] + [train_x_embedding]\n",
    "\n",
    "val_data = [val_x_continue] + [val_x_category[:, i] \\\n",
    "            for i in range(val_x_category.shape[1])] + \\\n",
    "            [val_x_category_poly] + [val_x_embedding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_crossentropy(y_true, y_pred):\n",
    "    true = K.equal(y_true, 1.0 ) \n",
    "    true2 = K.cast(true , dtype = float)\n",
    "    return K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1)\n",
    "\n",
    "gamma = 2.0\n",
    "epsilon = K.epsilon()\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    # https://www.kaggle.com/mathormad/resnet50-v2-keras-focal-loss-mix-up\n",
    "    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n",
    "    pt = K.clip(pt, epsilon, 1-epsilon)\n",
    "    CE = -K.log(pt)\n",
    "    FL = K.pow(1-pt, gamma) * CE\n",
    "    loss = K.sum(FL, axis=1)\n",
    "    return loss\n",
    "    return K.mean(K.sum(loss, axis=1))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr, beta_1=beta_1),\n",
    "              loss=focal_loss   , # focal_loss  ,  # 'binary_crossentropy',\n",
    "              metrics=[ binary_crossentropy ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"./ckpt/my_checkpoint/KM-{epoch:04d}.ckpt\"\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 save_best_only = True , \n",
    "                                                 save_freq = 'epoch' , \n",
    "                                                 mode='auto' ,\n",
    "                                                 verbose=1)\n",
    "# step 별로 learning rate를 조절합니다. \n",
    "def step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=10):\n",
    "    def schedule(epoch):\n",
    "        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
    "    \n",
    "    return tf.keras.callbacks.LearningRateScheduler(schedule)\n",
    "\n",
    "lr_sched = step_decay_schedule(initial_lr=lr, decay_factor=0.8, step_size=2)\n",
    "\n",
    "  # `val_loss`가 2번의 에포크에 걸쳐 향상되지 않으면 훈련을 멈춥니다.\n",
    "Early = tf.keras.callbacks.EarlyStopping(min_delta=0.0001, \n",
    "                                         patience=10 ,\n",
    "                                         monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4398/4408 [============================>.] - ETA: 0s - loss: 44.7882 - binary_crossentropy: 0.2894\n",
      "Epoch 00001: val_loss improved from inf to 2.96149, saving model to ./ckpt/my_checkpoint/KM-0001.ckpt\n",
      "WARNING:tensorflow:From /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/aiffel0042/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0001.ckpt/assets\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 44.6995 - binary_crossentropy: 0.2890 - val_loss: 2.9615 - val_binary_crossentropy: 0.0701\n",
      "Epoch 2/500\n",
      "4393/4408 [============================>.] - ETA: 0s - loss: 2.4240 - binary_crossentropy: 0.0625\n",
      "Epoch 00002: val_loss improved from 2.96149 to 2.15044, saving model to ./ckpt/my_checkpoint/KM-0002.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0002.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 2.4231 - binary_crossentropy: 0.0625 - val_loss: 2.1504 - val_binary_crossentropy: 0.0616\n",
      "Epoch 3/500\n",
      "4391/4408 [============================>.] - ETA: 0s - loss: 1.9965 - binary_crossentropy: 0.0625\n",
      "Epoch 00003: val_loss improved from 2.15044 to 1.90558, saving model to ./ckpt/my_checkpoint/KM-0003.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0003.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.9961 - binary_crossentropy: 0.0625 - val_loss: 1.9056 - val_binary_crossentropy: 0.0622\n",
      "Epoch 4/500\n",
      "4397/4408 [============================>.] - ETA: 0s - loss: 1.8231 - binary_crossentropy: 0.0635\n",
      "Epoch 00004: val_loss improved from 1.90558 to 1.77887, saving model to ./ckpt/my_checkpoint/KM-0004.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0004.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.8229 - binary_crossentropy: 0.0635 - val_loss: 1.7789 - val_binary_crossentropy: 0.0634\n",
      "Epoch 5/500\n",
      "4396/4408 [============================>.] - ETA: 0s - loss: 1.7351 - binary_crossentropy: 0.0643\n",
      "Epoch 00005: val_loss improved from 1.77887 to 1.71889, saving model to ./ckpt/my_checkpoint/KM-0005.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0005.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.7350 - binary_crossentropy: 0.0643 - val_loss: 1.7189 - val_binary_crossentropy: 0.0636\n",
      "Epoch 6/500\n",
      "4391/4408 [============================>.] - ETA: 0s - loss: 1.6864 - binary_crossentropy: 0.0648\n",
      "Epoch 00006: val_loss improved from 1.71889 to 1.67633, saving model to ./ckpt/my_checkpoint/KM-0006.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0006.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.6864 - binary_crossentropy: 0.0648 - val_loss: 1.6763 - val_binary_crossentropy: 0.0639\n",
      "Epoch 7/500\n",
      "4391/4408 [============================>.] - ETA: 0s - loss: 1.6540 - binary_crossentropy: 0.0652\n",
      "Epoch 00007: val_loss improved from 1.67633 to 1.65201, saving model to ./ckpt/my_checkpoint/KM-0007.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0007.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.6540 - binary_crossentropy: 0.0652 - val_loss: 1.6520 - val_binary_crossentropy: 0.0642\n",
      "Epoch 8/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.6325 - binary_crossentropy: 0.0655\n",
      "Epoch 00008: val_loss improved from 1.65201 to 1.63312, saving model to ./ckpt/my_checkpoint/KM-0008.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0008.ckpt/assets\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.6325 - binary_crossentropy: 0.0655 - val_loss: 1.6331 - val_binary_crossentropy: 0.0644\n",
      "Epoch 9/500\n",
      "4398/4408 [============================>.] - ETA: 0s - loss: 1.6170 - binary_crossentropy: 0.0656\n",
      "Epoch 00009: val_loss improved from 1.63312 to 1.62024, saving model to ./ckpt/my_checkpoint/KM-0009.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0009.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.6170 - binary_crossentropy: 0.0657 - val_loss: 1.6202 - val_binary_crossentropy: 0.0646\n",
      "Epoch 10/500\n",
      "4408/4408 [==============================] - ETA: 0s - loss: 1.6044 - binary_crossentropy: 0.0658\n",
      "Epoch 00010: val_loss improved from 1.62024 to 1.60868, saving model to ./ckpt/my_checkpoint/KM-0010.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0010.ckpt/assets\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.6044 - binary_crossentropy: 0.0658 - val_loss: 1.6087 - val_binary_crossentropy: 0.0648\n",
      "Epoch 11/500\n",
      "4395/4408 [============================>.] - ETA: 0s - loss: 1.5943 - binary_crossentropy: 0.0659\n",
      "Epoch 00011: val_loss improved from 1.60868 to 1.60092, saving model to ./ckpt/my_checkpoint/KM-0011.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0011.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5943 - binary_crossentropy: 0.0659 - val_loss: 1.6009 - val_binary_crossentropy: 0.0649\n",
      "Epoch 12/500\n",
      "4399/4408 [============================>.] - ETA: 0s - loss: 1.5870 - binary_crossentropy: 0.0660\n",
      "Epoch 00012: val_loss improved from 1.60092 to 1.59499, saving model to ./ckpt/my_checkpoint/KM-0012.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0012.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5870 - binary_crossentropy: 0.0660 - val_loss: 1.5950 - val_binary_crossentropy: 0.0645\n",
      "Epoch 13/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5806 - binary_crossentropy: 0.0660\n",
      "Epoch 00013: val_loss improved from 1.59499 to 1.58984, saving model to ./ckpt/my_checkpoint/KM-0013.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0013.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5806 - binary_crossentropy: 0.0660 - val_loss: 1.5898 - val_binary_crossentropy: 0.0644\n",
      "Epoch 14/500\n",
      "4403/4408 [============================>.] - ETA: 0s - loss: 1.5750 - binary_crossentropy: 0.0661\n",
      "Epoch 00014: val_loss improved from 1.58984 to 1.58441, saving model to ./ckpt/my_checkpoint/KM-0014.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0014.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5750 - binary_crossentropy: 0.0661 - val_loss: 1.5844 - val_binary_crossentropy: 0.0648\n",
      "Epoch 15/500\n",
      "4403/4408 [============================>.] - ETA: 0s - loss: 1.5708 - binary_crossentropy: 0.0661\n",
      "Epoch 00015: val_loss improved from 1.58441 to 1.58249, saving model to ./ckpt/my_checkpoint/KM-0015.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0015.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5708 - binary_crossentropy: 0.0661 - val_loss: 1.5825 - val_binary_crossentropy: 0.0645\n",
      "Epoch 16/500\n",
      "4394/4408 [============================>.] - ETA: 0s - loss: 1.5669 - binary_crossentropy: 0.0662\n",
      "Epoch 00016: val_loss improved from 1.58249 to 1.57762, saving model to ./ckpt/my_checkpoint/KM-0016.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0016.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5669 - binary_crossentropy: 0.0662 - val_loss: 1.5776 - val_binary_crossentropy: 0.0647\n",
      "Epoch 17/500\n",
      "4401/4408 [============================>.] - ETA: 0s - loss: 1.5636 - binary_crossentropy: 0.0662\n",
      "Epoch 00017: val_loss improved from 1.57762 to 1.57565, saving model to ./ckpt/my_checkpoint/KM-0017.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0017.ckpt/assets\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5637 - binary_crossentropy: 0.0662 - val_loss: 1.5757 - val_binary_crossentropy: 0.0648\n",
      "Epoch 18/500\n",
      "4406/4408 [============================>.] - ETA: 0s - loss: 1.5610 - binary_crossentropy: 0.0662\n",
      "Epoch 00018: val_loss improved from 1.57565 to 1.57312, saving model to ./ckpt/my_checkpoint/KM-0018.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0018.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5610 - binary_crossentropy: 0.0662 - val_loss: 1.5731 - val_binary_crossentropy: 0.0649\n",
      "Epoch 19/500\n",
      "4405/4408 [============================>.] - ETA: 0s - loss: 1.5584 - binary_crossentropy: 0.0662\n",
      "Epoch 00019: val_loss improved from 1.57312 to 1.57108, saving model to ./ckpt/my_checkpoint/KM-0019.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0019.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5584 - binary_crossentropy: 0.0662 - val_loss: 1.5711 - val_binary_crossentropy: 0.0648\n",
      "Epoch 20/500\n",
      "4396/4408 [============================>.] - ETA: 0s - loss: 1.5563 - binary_crossentropy: 0.0662\n",
      "Epoch 00020: val_loss improved from 1.57108 to 1.56892, saving model to ./ckpt/my_checkpoint/KM-0020.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0020.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5563 - binary_crossentropy: 0.0662 - val_loss: 1.5689 - val_binary_crossentropy: 0.0653\n",
      "Epoch 21/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5545 - binary_crossentropy: 0.0662\n",
      "Epoch 00021: val_loss improved from 1.56892 to 1.56799, saving model to ./ckpt/my_checkpoint/KM-0021.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0021.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5545 - binary_crossentropy: 0.0662 - val_loss: 1.5680 - val_binary_crossentropy: 0.0649\n",
      "Epoch 22/500\n",
      "4398/4408 [============================>.] - ETA: 0s - loss: 1.5531 - binary_crossentropy: 0.0663\n",
      "Epoch 00022: val_loss improved from 1.56799 to 1.56577, saving model to ./ckpt/my_checkpoint/KM-0022.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0022.ckpt/assets\n",
      "4408/4408 [==============================] - 17s 4ms/step - loss: 1.5531 - binary_crossentropy: 0.0663 - val_loss: 1.5658 - val_binary_crossentropy: 0.0650\n",
      "Epoch 23/500\n",
      "4401/4408 [============================>.] - ETA: 0s - loss: 1.5515 - binary_crossentropy: 0.0663\n",
      "Epoch 00023: val_loss improved from 1.56577 to 1.56501, saving model to ./ckpt/my_checkpoint/KM-0023.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0023.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5515 - binary_crossentropy: 0.0663 - val_loss: 1.5650 - val_binary_crossentropy: 0.0649\n",
      "Epoch 24/500\n",
      "4395/4408 [============================>.] - ETA: 0s - loss: 1.5503 - binary_crossentropy: 0.0662\n",
      "Epoch 00024: val_loss improved from 1.56501 to 1.56346, saving model to ./ckpt/my_checkpoint/KM-0024.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0024.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5503 - binary_crossentropy: 0.0662 - val_loss: 1.5635 - val_binary_crossentropy: 0.0653\n",
      "Epoch 25/500\n",
      "4400/4408 [============================>.] - ETA: 0s - loss: 1.5492 - binary_crossentropy: 0.0663\n",
      "Epoch 00025: val_loss did not improve from 1.56346\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5491 - binary_crossentropy: 0.0663 - val_loss: 1.5636 - val_binary_crossentropy: 0.0649\n",
      "Epoch 26/500\n",
      "4393/4408 [============================>.] - ETA: 0s - loss: 1.5484 - binary_crossentropy: 0.0663\n",
      "Epoch 00026: val_loss improved from 1.56346 to 1.56288, saving model to ./ckpt/my_checkpoint/KM-0026.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0026.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5484 - binary_crossentropy: 0.0663 - val_loss: 1.5629 - val_binary_crossentropy: 0.0651\n",
      "Epoch 27/500\n",
      "4400/4408 [============================>.] - ETA: 0s - loss: 1.5475 - binary_crossentropy: 0.0663\n",
      "Epoch 00027: val_loss improved from 1.56288 to 1.56166, saving model to ./ckpt/my_checkpoint/KM-0027.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0027.ckpt/assets\n",
      "4408/4408 [==============================] - 17s 4ms/step - loss: 1.5474 - binary_crossentropy: 0.0663 - val_loss: 1.5617 - val_binary_crossentropy: 0.0649\n",
      "Epoch 28/500\n",
      "4397/4408 [============================>.] - ETA: 0s - loss: 1.5468 - binary_crossentropy: 0.0663\n",
      "Epoch 00028: val_loss improved from 1.56166 to 1.56161, saving model to ./ckpt/my_checkpoint/KM-0028.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0028.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5467 - binary_crossentropy: 0.0663 - val_loss: 1.5616 - val_binary_crossentropy: 0.0652\n",
      "Epoch 29/500\n",
      "4396/4408 [============================>.] - ETA: 0s - loss: 1.5459 - binary_crossentropy: 0.0663\n",
      "Epoch 00029: val_loss improved from 1.56161 to 1.56017, saving model to ./ckpt/my_checkpoint/KM-0029.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0029.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5460 - binary_crossentropy: 0.0663 - val_loss: 1.5602 - val_binary_crossentropy: 0.0651\n",
      "Epoch 30/500\n",
      "4408/4408 [==============================] - ETA: 0s - loss: 1.5455 - binary_crossentropy: 0.0663\n",
      "Epoch 00030: val_loss did not improve from 1.56017\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5455 - binary_crossentropy: 0.0663 - val_loss: 1.5606 - val_binary_crossentropy: 0.0648\n",
      "Epoch 31/500\n",
      "4408/4408 [==============================] - ETA: 0s - loss: 1.5451 - binary_crossentropy: 0.0663\n",
      "Epoch 00031: val_loss improved from 1.56017 to 1.55944, saving model to ./ckpt/my_checkpoint/KM-0031.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0031.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5451 - binary_crossentropy: 0.0663 - val_loss: 1.5594 - val_binary_crossentropy: 0.0651\n",
      "Epoch 32/500\n",
      "4401/4408 [============================>.] - ETA: 0s - loss: 1.5447 - binary_crossentropy: 0.0663\n",
      "Epoch 00032: val_loss did not improve from 1.55944\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5447 - binary_crossentropy: 0.0663 - val_loss: 1.5597 - val_binary_crossentropy: 0.0651\n",
      "Epoch 33/500\n",
      "4403/4408 [============================>.] - ETA: 0s - loss: 1.5439 - binary_crossentropy: 0.0663\n",
      "Epoch 00033: val_loss improved from 1.55944 to 1.55938, saving model to ./ckpt/my_checkpoint/KM-0033.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0033.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5440 - binary_crossentropy: 0.0663 - val_loss: 1.5594 - val_binary_crossentropy: 0.0648\n",
      "Epoch 34/500\n",
      "4398/4408 [============================>.] - ETA: 0s - loss: 1.5435 - binary_crossentropy: 0.0663\n",
      "Epoch 00034: val_loss improved from 1.55938 to 1.55927, saving model to ./ckpt/my_checkpoint/KM-0034.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0034.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5435 - binary_crossentropy: 0.0663 - val_loss: 1.5593 - val_binary_crossentropy: 0.0650\n",
      "Epoch 35/500\n",
      "4397/4408 [============================>.] - ETA: 0s - loss: 1.5434 - binary_crossentropy: 0.0663\n",
      "Epoch 00035: val_loss improved from 1.55927 to 1.55824, saving model to ./ckpt/my_checkpoint/KM-0035.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0035.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5433 - binary_crossentropy: 0.0663 - val_loss: 1.5582 - val_binary_crossentropy: 0.0652\n",
      "Epoch 36/500\n",
      "4403/4408 [============================>.] - ETA: 0s - loss: 1.5431 - binary_crossentropy: 0.0663\n",
      "Epoch 00036: val_loss improved from 1.55824 to 1.55780, saving model to ./ckpt/my_checkpoint/KM-0036.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0036.ckpt/assets\n",
      "4408/4408 [==============================] - 17s 4ms/step - loss: 1.5432 - binary_crossentropy: 0.0663 - val_loss: 1.5578 - val_binary_crossentropy: 0.0649\n",
      "Epoch 37/500\n",
      "4399/4408 [============================>.] - ETA: 0s - loss: 1.5427 - binary_crossentropy: 0.0663\n",
      "Epoch 00037: val_loss did not improve from 1.55780\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5427 - binary_crossentropy: 0.0663 - val_loss: 1.5582 - val_binary_crossentropy: 0.0651\n",
      "Epoch 38/500\n",
      "4407/4408 [============================>.] - ETA: 0s - loss: 1.5426 - binary_crossentropy: 0.0663\n",
      "Epoch 00038: val_loss did not improve from 1.55780\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5426 - binary_crossentropy: 0.0663 - val_loss: 1.5580 - val_binary_crossentropy: 0.0650\n",
      "Epoch 39/500\n",
      "4393/4408 [============================>.] - ETA: 0s - loss: 1.5421 - binary_crossentropy: 0.0663\n",
      "Epoch 00039: val_loss improved from 1.55780 to 1.55764, saving model to ./ckpt/my_checkpoint/KM-0039.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0039.ckpt/assets\n",
      "4408/4408 [==============================] - 15s 4ms/step - loss: 1.5421 - binary_crossentropy: 0.0663 - val_loss: 1.5576 - val_binary_crossentropy: 0.0651\n",
      "Epoch 40/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5423 - binary_crossentropy: 0.0663\n",
      "Epoch 00040: val_loss improved from 1.55764 to 1.55731, saving model to ./ckpt/my_checkpoint/KM-0040.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0040.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5423 - binary_crossentropy: 0.0663 - val_loss: 1.5573 - val_binary_crossentropy: 0.0651\n",
      "Epoch 41/500\n",
      "4393/4408 [============================>.] - ETA: 0s - loss: 1.5419 - binary_crossentropy: 0.0663\n",
      "Epoch 00041: val_loss improved from 1.55731 to 1.55717, saving model to ./ckpt/my_checkpoint/KM-0041.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0041.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5419 - binary_crossentropy: 0.0663 - val_loss: 1.5572 - val_binary_crossentropy: 0.0651\n",
      "Epoch 42/500\n",
      "4407/4408 [============================>.] - ETA: 0s - loss: 1.5417 - binary_crossentropy: 0.0663\n",
      "Epoch 00042: val_loss did not improve from 1.55717\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5417 - binary_crossentropy: 0.0663 - val_loss: 1.5573 - val_binary_crossentropy: 0.0652\n",
      "Epoch 43/500\n",
      "4396/4408 [============================>.] - ETA: 0s - loss: 1.5414 - binary_crossentropy: 0.0663\n",
      "Epoch 00043: val_loss did not improve from 1.55717\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5415 - binary_crossentropy: 0.0663 - val_loss: 1.5573 - val_binary_crossentropy: 0.0652\n",
      "Epoch 44/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5416 - binary_crossentropy: 0.0663\n",
      "Epoch 00044: val_loss did not improve from 1.55717\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5416 - binary_crossentropy: 0.0663 - val_loss: 1.5572 - val_binary_crossentropy: 0.0648\n",
      "Epoch 45/500\n",
      "4405/4408 [============================>.] - ETA: 0s - loss: 1.5416 - binary_crossentropy: 0.0663\n",
      "Epoch 00045: val_loss improved from 1.55717 to 1.55672, saving model to ./ckpt/my_checkpoint/KM-0045.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0045.ckpt/assets\n",
      "4408/4408 [==============================] - 17s 4ms/step - loss: 1.5416 - binary_crossentropy: 0.0663 - val_loss: 1.5567 - val_binary_crossentropy: 0.0649\n",
      "Epoch 46/500\n",
      "4403/4408 [============================>.] - ETA: 0s - loss: 1.5415 - binary_crossentropy: 0.0663\n",
      "Epoch 00046: val_loss did not improve from 1.55672\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5415 - binary_crossentropy: 0.0663 - val_loss: 1.5571 - val_binary_crossentropy: 0.0653\n",
      "Epoch 47/500\n",
      "4396/4408 [============================>.] - ETA: 0s - loss: 1.5412 - binary_crossentropy: 0.0663\n",
      "Epoch 00047: val_loss did not improve from 1.55672\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5413 - binary_crossentropy: 0.0663 - val_loss: 1.5569 - val_binary_crossentropy: 0.0653\n",
      "Epoch 48/500\n",
      "4406/4408 [============================>.] - ETA: 0s - loss: 1.5411 - binary_crossentropy: 0.0663\n",
      "Epoch 00048: val_loss improved from 1.55672 to 1.55626, saving model to ./ckpt/my_checkpoint/KM-0048.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0048.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5411 - binary_crossentropy: 0.0663 - val_loss: 1.5563 - val_binary_crossentropy: 0.0653\n",
      "Epoch 49/500\n",
      "4397/4408 [============================>.] - ETA: 0s - loss: 1.5412 - binary_crossentropy: 0.0663\n",
      "Epoch 00049: val_loss did not improve from 1.55626\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5413 - binary_crossentropy: 0.0663 - val_loss: 1.5569 - val_binary_crossentropy: 0.0650\n",
      "Epoch 50/500\n",
      "4397/4408 [============================>.] - ETA: 0s - loss: 1.5412 - binary_crossentropy: 0.0663\n",
      "Epoch 00050: val_loss did not improve from 1.55626\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5412 - binary_crossentropy: 0.0663 - val_loss: 1.5568 - val_binary_crossentropy: 0.0650\n",
      "Epoch 51/500\n",
      "4395/4408 [============================>.] - ETA: 0s - loss: 1.5411 - binary_crossentropy: 0.0663\n",
      "Epoch 00051: val_loss did not improve from 1.55626\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5411 - binary_crossentropy: 0.0663 - val_loss: 1.5564 - val_binary_crossentropy: 0.0653\n",
      "Epoch 52/500\n",
      "4394/4408 [============================>.] - ETA: 0s - loss: 1.5411 - binary_crossentropy: 0.0663\n",
      "Epoch 00052: val_loss improved from 1.55626 to 1.55625, saving model to ./ckpt/my_checkpoint/KM-0052.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0052.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5411 - binary_crossentropy: 0.0663 - val_loss: 1.5562 - val_binary_crossentropy: 0.0652\n",
      "Epoch 53/500\n",
      "4393/4408 [============================>.] - ETA: 0s - loss: 1.5411 - binary_crossentropy: 0.0663\n",
      "Epoch 00053: val_loss did not improve from 1.55625\n",
      "4408/4408 [==============================] - 15s 3ms/step - loss: 1.5411 - binary_crossentropy: 0.0663 - val_loss: 1.5573 - val_binary_crossentropy: 0.0648\n",
      "Epoch 54/500\n",
      "4402/4408 [============================>.] - ETA: 0s - loss: 1.5410 - binary_crossentropy: 0.0663\n",
      "Epoch 00054: val_loss did not improve from 1.55625\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5410 - binary_crossentropy: 0.0663 - val_loss: 1.5564 - val_binary_crossentropy: 0.0650\n",
      "Epoch 55/500\n",
      "4406/4408 [============================>.] - ETA: 0s - loss: 1.5409 - binary_crossentropy: 0.0663\n",
      "Epoch 00055: val_loss did not improve from 1.55625\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5409 - binary_crossentropy: 0.0663 - val_loss: 1.5567 - val_binary_crossentropy: 0.0652\n",
      "Epoch 56/500\n",
      "4397/4408 [============================>.] - ETA: 0s - loss: 1.5409 - binary_crossentropy: 0.0663\n",
      "Epoch 00056: val_loss did not improve from 1.55625\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5410 - binary_crossentropy: 0.0663 - val_loss: 1.5564 - val_binary_crossentropy: 0.0653\n",
      "Epoch 57/500\n",
      "4390/4408 [============================>.] - ETA: 0s - loss: 1.5411 - binary_crossentropy: 0.0663\n",
      "Epoch 00057: val_loss improved from 1.55625 to 1.55588, saving model to ./ckpt/my_checkpoint/KM-0057.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0057.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5411 - binary_crossentropy: 0.0663 - val_loss: 1.5559 - val_binary_crossentropy: 0.0651\n",
      "Epoch 58/500\n",
      "4408/4408 [==============================] - ETA: 0s - loss: 1.5406 - binary_crossentropy: 0.0663\n",
      "Epoch 00058: val_loss did not improve from 1.55588\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5406 - binary_crossentropy: 0.0663 - val_loss: 1.5563 - val_binary_crossentropy: 0.0651\n",
      "Epoch 59/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5410 - binary_crossentropy: 0.0663\n",
      "Epoch 00059: val_loss did not improve from 1.55588\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5410 - binary_crossentropy: 0.0663 - val_loss: 1.5562 - val_binary_crossentropy: 0.0652\n",
      "Epoch 60/500\n",
      "4388/4408 [============================>.] - ETA: 0s - loss: 1.5407 - binary_crossentropy: 0.0663\n",
      "Epoch 00060: val_loss did not improve from 1.55588\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5407 - binary_crossentropy: 0.0663 - val_loss: 1.5562 - val_binary_crossentropy: 0.0650\n",
      "Epoch 61/500\n",
      "4399/4408 [============================>.] - ETA: 0s - loss: 1.5408 - binary_crossentropy: 0.0663\n",
      "Epoch 00061: val_loss did not improve from 1.55588\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5409 - binary_crossentropy: 0.0663 - val_loss: 1.5565 - val_binary_crossentropy: 0.0653\n",
      "Epoch 62/500\n",
      "4390/4408 [============================>.] - ETA: 0s - loss: 1.5405 - binary_crossentropy: 0.0663\n",
      "Epoch 00062: val_loss did not improve from 1.55588\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5407 - binary_crossentropy: 0.0663 - val_loss: 1.5564 - val_binary_crossentropy: 0.0651\n",
      "Epoch 63/500\n",
      "4390/4408 [============================>.] - ETA: 0s - loss: 1.5407 - binary_crossentropy: 0.0664\n",
      "Epoch 00063: val_loss did not improve from 1.55588\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5408 - binary_crossentropy: 0.0664 - val_loss: 1.5566 - val_binary_crossentropy: 0.0652\n",
      "Epoch 64/500\n",
      "4393/4408 [============================>.] - ETA: 0s - loss: 1.5412 - binary_crossentropy: 0.0664\n",
      "Epoch 00064: val_loss did not improve from 1.55588\n",
      "4408/4408 [==============================] - 14s 3ms/step - loss: 1.5411 - binary_crossentropy: 0.0664 - val_loss: 1.5563 - val_binary_crossentropy: 0.0653\n",
      "Epoch 65/500\n",
      "4404/4408 [============================>.] - ETA: 0s - loss: 1.5407 - binary_crossentropy: 0.0664\n",
      "Epoch 00065: val_loss did not improve from 1.55588\n",
      "4408/4408 [==============================] - 12s 3ms/step - loss: 1.5407 - binary_crossentropy: 0.0664 - val_loss: 1.5561 - val_binary_crossentropy: 0.0651\n",
      "Epoch 66/500\n",
      "4399/4408 [============================>.] - ETA: 0s - loss: 1.5407 - binary_crossentropy: 0.0664\n",
      "Epoch 00066: val_loss did not improve from 1.55588\n",
      "4408/4408 [==============================] - 13s 3ms/step - loss: 1.5406 - binary_crossentropy: 0.0664 - val_loss: 1.5563 - val_binary_crossentropy: 0.0654\n",
      "Epoch 67/500\n",
      "4407/4408 [============================>.] - ETA: 0s - loss: 1.5408 - binary_crossentropy: 0.0664\n",
      "Epoch 00067: val_loss improved from 1.55588 to 1.55580, saving model to ./ckpt/my_checkpoint/KM-0067.ckpt\n",
      "INFO:tensorflow:Assets written to: ./ckpt/my_checkpoint/KM-0067.ckpt/assets\n",
      "4408/4408 [==============================] - 16s 4ms/step - loss: 1.5408 - binary_crossentropy: 0.0664 - val_loss: 1.5558 - val_binary_crossentropy: 0.0652\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(input_data, train_y, \n",
    "                  epochs=epochs, \n",
    "                  batch_size=batch_size, \n",
    "                  validation_data=(val_data, val_y), \n",
    "                  callbacks=[lr_sched, Early, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/widendeep_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./model/widendeep_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4294030ad0>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train input data와 같은 방식으로 test data를 input 형식에 맞추어줌\n",
    "eval_input_data = [test_x_continue] + [test_x_category[:, i] for i in range(test_x_category.shape[1])] + [test_x_category_poly] + [test_x_embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1031/1031 [==============================] - 1s 1ms/step - loss: 1.5621 - binary_crossentropy: 0.0655\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(eval_input_data, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model.predict(eval_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = data.loc[test_x.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot에서 같은 trans_id는 더해줌.\n",
    "receipt_y = test_y.copy()\n",
    "receipt_y['trans_id'] = test_x['trans_id']\n",
    "frame = pd.DataFrame(data = receipt_y['trans_id'], columns=['trans_id'])\n",
    "receipt_y = receipt_y.groupby('trans_id', as_index=False).sum()\n",
    "receipt_y = frame.merge(receipt_y, how='left').set_index(test_x.index)\n",
    "receipt_y.drop('trans_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chilled Snacks</th>\n",
       "      <th>Snacks</th>\n",
       "      <th>Hot Snacks</th>\n",
       "      <th>Women's Upper Bodywear / Tops</th>\n",
       "      <th>Chilled Instant Foods</th>\n",
       "      <th>Bakery</th>\n",
       "      <th>Lighting Accessories</th>\n",
       "      <th>Biscuits</th>\n",
       "      <th>Ham and Sausages</th>\n",
       "      <th>Fish Cakes and Crab Sticks</th>\n",
       "      <th>...</th>\n",
       "      <th>Other Ball Game / Field Sports</th>\n",
       "      <th>Grain Gift Sets</th>\n",
       "      <th>Sea Food Gift Sets</th>\n",
       "      <th>Car Accessories</th>\n",
       "      <th>Business Paper Products</th>\n",
       "      <th>Writing Supplies</th>\n",
       "      <th>Vegetable Gift Sets</th>\n",
       "      <th>Car Wash Equipment</th>\n",
       "      <th>Safety Equipment</th>\n",
       "      <th>Improvement Supplies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>626819</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626820</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626821</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626822</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626823</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Chilled Snacks  Snacks  Hot Snacks  Women's Upper Bodywear / Tops  \\\n",
       "626819             NaN     NaN         NaN                            NaN   \n",
       "626820             NaN     NaN         NaN                            NaN   \n",
       "626821             NaN     NaN         NaN                            NaN   \n",
       "626822             0.0     0.0         0.0                            0.0   \n",
       "626823             NaN     NaN         NaN                            NaN   \n",
       "\n",
       "        Chilled Instant Foods  Bakery  Lighting Accessories  Biscuits  \\\n",
       "626819                    NaN     NaN                   NaN       NaN   \n",
       "626820                    NaN     NaN                   NaN       NaN   \n",
       "626821                    NaN     NaN                   NaN       NaN   \n",
       "626822                    0.0     0.0                   0.0       0.0   \n",
       "626823                    NaN     NaN                   NaN       NaN   \n",
       "\n",
       "        Ham and Sausages  Fish Cakes and Crab Sticks  ...  \\\n",
       "626819               NaN                         NaN  ...   \n",
       "626820               NaN                         NaN  ...   \n",
       "626821               NaN                         NaN  ...   \n",
       "626822               0.0                         0.0  ...   \n",
       "626823               NaN                         NaN  ...   \n",
       "\n",
       "        Other Ball Game / Field Sports  Grain Gift Sets  Sea Food Gift Sets  \\\n",
       "626819                             NaN              NaN                 NaN   \n",
       "626820                             NaN              NaN                 NaN   \n",
       "626821                             NaN              NaN                 NaN   \n",
       "626822                             0.0              0.0                 0.0   \n",
       "626823                             NaN              NaN                 NaN   \n",
       "\n",
       "        Car Accessories  Business Paper Products  Writing Supplies  \\\n",
       "626819              NaN                      NaN               NaN   \n",
       "626820              NaN                      NaN               NaN   \n",
       "626821              NaN                      NaN               NaN   \n",
       "626822              0.0                      0.0               0.0   \n",
       "626823              NaN                      NaN               NaN   \n",
       "\n",
       "        Vegetable Gift Sets  Car Wash Equipment  Safety Equipment  \\\n",
       "626819                  NaN                 NaN               NaN   \n",
       "626820                  NaN                 NaN               NaN   \n",
       "626821                  NaN                 NaN               NaN   \n",
       "626822                  0.0                 0.0               0.0   \n",
       "626823                  NaN                 NaN               NaN   \n",
       "\n",
       "        Improvement Supplies  \n",
       "626819                   NaN  \n",
       "626820                   NaN  \n",
       "626821                   NaN  \n",
       "626822                   0.0  \n",
       "626823                   NaN  \n",
       "\n",
       "[5 rows x 309 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receipt_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 같은 영수증 별로 구매 아이템을 묶어주는 작업.\n",
    "test_label = data.loc[test_x.index][['clnt_id','sess_id', 'clac_nm2']]\n",
    "frame = pd.DataFrame(data = test_label[['clnt_id','sess_id']], columns=['clnt_id', 'sess_id'])\n",
    "test_label = test_label.groupby(['clnt_id','sess_id'])['clac_nm2'].apply(lambda x: ', '.join(x))\n",
    "test_label = frame.merge(test_label, on=['clnt_id', 'sess_id'],how='left').set_index(test_x.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>sess_id</th>\n",
       "      <th>clac_nm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>626832</th>\n",
       "      <td>31350</td>\n",
       "      <td>91</td>\n",
       "      <td>Women's Lower Bodywear / Bottoms, Women's Lowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626833</th>\n",
       "      <td>37794</td>\n",
       "      <td>114</td>\n",
       "      <td>Traditional Rice Cakes, Hot Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626834</th>\n",
       "      <td>37794</td>\n",
       "      <td>114</td>\n",
       "      <td>Traditional Rice Cakes, Hot Snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626835</th>\n",
       "      <td>54771</td>\n",
       "      <td>40</td>\n",
       "      <td>Fish Cakes and Crab Sticks, Girl's Toys, Chill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626836</th>\n",
       "      <td>54771</td>\n",
       "      <td>40</td>\n",
       "      <td>Fish Cakes and Crab Sticks, Girl's Toys, Chill...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        clnt_id  sess_id                                           clac_nm2\n",
       "626832    31350       91  Women's Lower Bodywear / Bottoms, Women's Lowe...\n",
       "626833    37794      114                 Traditional Rice Cakes, Hot Snacks\n",
       "626834    37794      114                 Traditional Rice Cakes, Hot Snacks\n",
       "626835    54771       40  Fish Cakes and Crab Sticks, Girl's Toys, Chill...\n",
       "626836    54771       40  Fish Cakes and Crab Sticks, Girl's Toys, Chill..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.head(18).tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pd = pd.DataFrame(prob, columns=receipt_y.columns)\n",
    "cond = list(np.sum(receipt_y.values, axis=1) > 10)\n",
    "cond_pd = score_pd[cond].reset_index(drop= True)\n",
    "test_pd = test_label[cond].reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "pred_matrix: 예측된 아이템 행렬 파라미터.\n",
    "top_n: 상위 몇개를 추천으로 사용할 지 정하는 파라미터.\n",
    "test_matix: 고객ID와 Target이 있는 행렬 파라미터\n",
    "'''\n",
    "def get_acc(score_matrix, top_n, test_matix):\n",
    "    avg_acc = 0\n",
    "    match_list = []\n",
    "    for i in range(len(score_matrix)):\n",
    "        top = score_matrix.iloc[i].nlargest(top_n).index\n",
    "        tmp = 0\n",
    "        match = np.zeros(top_n).astype(np.int8).tolist()\n",
    "        for j in range(len(top)):\n",
    "            true_buy = [k for k in test_matix[\"clac_nm2\"][i].split(', ')]\n",
    "            if top[j] in true_buy :\n",
    "                tmp += 1\n",
    "                match[j] = 1\n",
    "        match_list.append(match)\n",
    "        acc = tmp / len(top)\n",
    "        avg_acc += acc / len(score_matrix)\n",
    "    print(\"Accuracy of Top {}: {:>.3f}%\\n\".format(top_n, avg_acc*100))\n",
    "    return avg_acc, match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(r, k):\n",
    "    assert k >= 1\n",
    "    r = np.asarray(r)[:k] != 0\n",
    "    if r.size != k:\n",
    "        raise ValueError('Relevance score length < k')\n",
    "    return np.mean(r)\n",
    "\n",
    "\n",
    "def average_precision(r):\n",
    "    r = np.asarray(r) != 0\n",
    "    out = [precision_at_k(r, k + 1) for k in range(r.size) if r[k]]\n",
    "    if not out:\n",
    "        return 0.\n",
    "    return np.mean(out)\n",
    "    \n",
    "def mean_average_precision(rs):\n",
    "    return np.mean([average_precision(r) for r in rs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Top 5: 7.573%\n",
      "\n",
      "MAP: 16.6%\n"
     ]
    }
   ],
   "source": [
    "accuracy, match_list =  get_acc(cond_pd, 5 , test_pd) \n",
    "map_val = mean_average_precision(match_list)\n",
    "print(\"MAP: {:.3}%\".format(map_val*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## 결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_list(predict_y, top_n, target_matrix):\n",
    "    test_matrix = target_matrix.copy()\n",
    "    pred_matrix = predict_y.copy()\n",
    "    for i in range(len(pred_matrix)):\n",
    "        top = pred_matrix.iloc[i].nlargest(top_n).index\n",
    "        top = pd.DataFrame(top.astype(str).to_frame().apply(lambda x: \", \".join(x)))\n",
    "        test_matrix.loc[i, 'pred'] = top.values[0]\n",
    "    return test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'word': clac_nm2, 'label': data['clac_nm2']}\n",
    "df = pd.DataFrame(data=d).drop_duplicates()\n",
    "cate2papago = df.set_index('label').to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_pred_list(cond_pd, 5, test_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.groupby('sess_id', as_index=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_to_item(test, column_name):\n",
    "    item_list = []\n",
    "    for i in range(test.shape[0]):\n",
    "        tmp_list = []\n",
    "        for a in test.iloc[i][column_name].split(', '):\n",
    "            tmp_list.append(a)\n",
    "        item_list.append(tmp_list)\n",
    "    return item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_id</th>\n",
       "      <th>clnt_id</th>\n",
       "      <th>clac_nm2</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7090</td>\n",
       "      <td>Instant Noodles, Dried Noodles, Dried Noodles,...</td>\n",
       "      <td>Leaf Vegetables, Fruit Vegetables, Dessert, An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>63998</td>\n",
       "      <td>Chilled Instant Foods, Lighting Accessories, F...</td>\n",
       "      <td>Fruit Vegetables, Kids' Underwear, Leaf Vegeta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60449</td>\n",
       "      <td>Packaged Side Dishes, Bakery, Hot Snacks, Seas...</td>\n",
       "      <td>Travel Bags, Fruit Vegetables, Fitness Trainin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>30297</td>\n",
       "      <td>Eggs, Processed Seaweeds, Processed Seaweeds, ...</td>\n",
       "      <td>Fruit Vegetables, Hand / Foot Care, Leaf Veget...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>24029</td>\n",
       "      <td>Chilled Snacks, Chilled Snacks, Bakery, Chille...</td>\n",
       "      <td>Hand / Foot Care, Fitness Training, Kids' Unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>130</td>\n",
       "      <td>45092</td>\n",
       "      <td>Ham and Sausages, Chilled Snacks, Ham and Saus...</td>\n",
       "      <td>Fruit Vegetables, Meat Gift Sets, Women's Gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>134</td>\n",
       "      <td>15518</td>\n",
       "      <td>Biscuits, Processed Milk, Frozen Instant Foods...</td>\n",
       "      <td>Meat Gift Sets, Boys' Full Bodywear, Hand / Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>138</td>\n",
       "      <td>35673</td>\n",
       "      <td>Mushrooms, Yogurt, Biscuits, Frozen Instant Fo...</td>\n",
       "      <td>Hand / Foot Care, Kids' Underwear, Yogurt, Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>196</td>\n",
       "      <td>62232</td>\n",
       "      <td>Leaf Vegetables, Frozen Instant Foods, Tissues...</td>\n",
       "      <td>Fruit Vegetables, Chilled Beverages, Girls' Ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>257</td>\n",
       "      <td>23121</td>\n",
       "      <td>Hot Snacks, Chilled Snacks, Snacks, Chocolates...</td>\n",
       "      <td>Improvement Supplies, Fruit Vegetables, Hand /...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sess_id  clnt_id                                           clac_nm2  \\\n",
       "0         1     7090  Instant Noodles, Dried Noodles, Dried Noodles,...   \n",
       "1         2    63998  Chilled Instant Foods, Lighting Accessories, F...   \n",
       "2         3    60449  Packaged Side Dishes, Bakery, Hot Snacks, Seas...   \n",
       "3         4    30297  Eggs, Processed Seaweeds, Processed Seaweeds, ...   \n",
       "4         5    24029  Chilled Snacks, Chilled Snacks, Bakery, Chille...   \n",
       "..      ...      ...                                                ...   \n",
       "75      130    45092  Ham and Sausages, Chilled Snacks, Ham and Saus...   \n",
       "76      134    15518  Biscuits, Processed Milk, Frozen Instant Foods...   \n",
       "77      138    35673  Mushrooms, Yogurt, Biscuits, Frozen Instant Fo...   \n",
       "78      196    62232  Leaf Vegetables, Frozen Instant Foods, Tissues...   \n",
       "79      257    23121  Hot Snacks, Chilled Snacks, Snacks, Chocolates...   \n",
       "\n",
       "                                                 pred  \n",
       "0   Leaf Vegetables, Fruit Vegetables, Dessert, An...  \n",
       "1   Fruit Vegetables, Kids' Underwear, Leaf Vegeta...  \n",
       "2   Travel Bags, Fruit Vegetables, Fitness Trainin...  \n",
       "3   Fruit Vegetables, Hand / Foot Care, Leaf Veget...  \n",
       "4   Hand / Foot Care, Fitness Training, Kids' Unde...  \n",
       "..                                                ...  \n",
       "75  Fruit Vegetables, Meat Gift Sets, Women's Gene...  \n",
       "76  Meat Gift Sets, Boys' Full Bodywear, Hand / Fo...  \n",
       "77  Hand / Foot Care, Kids' Underwear, Yogurt, Pre...  \n",
       "78  Fruit Vegetables, Chilled Beverages, Girls' Ou...  \n",
       "79  Improvement Supplies, Fruit Vegetables, Hand /...  \n",
       "\n",
       "[80 rows x 4 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dup(li):\n",
    "        my_set = set()\n",
    "        res = []\n",
    "        for e in li:\n",
    "            if e not in my_set:\n",
    "                res.append(e)\n",
    "                my_set.add(e)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(score_matrix, top_n, test_matix):\n",
    "    avg_acc = 0\n",
    "    match_list = []\n",
    "    for i in range(len(score_matrix)):\n",
    "        top = score_matrix.iloc[i].nlargest(top_n).index\n",
    "        tmp = 0\n",
    "        match = np.zeros(top_n).astype(np.int8).tolist()\n",
    "        for j in range(len(top)):\n",
    "            true_buy = [k.split(\", \")[0] for k in test_matix[\"clac_nm2\"][i].split()]\n",
    "            if top[j] in true_buy :\n",
    "                tmp += 1\n",
    "                match[j] = 1\n",
    "        match_list.append(match)\n",
    "        acc = tmp / len(top)\n",
    "        avg_acc += acc / len(score_matrix)\n",
    "    print(\"Hit rate of Top {}: {:>.5f}\".format(top_n, avg_acc))\n",
    "    return avg_acc, match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_with_table(a, b, index):\n",
    "    buy_list = remove_dup(a[index])\n",
    "    rec_list = remove_dup(b[index])\n",
    "    tmp=[]\n",
    "    match = np.zeros(len(b[index])).astype(np.int8).tolist()\n",
    "    for j in range(len(rec_list)):\n",
    "        if rec_list[j] in buy_list :\n",
    "            tmp.append(str(j)+'번째: '+rec_list[j])\n",
    "            match[j] = 1\n",
    "    df1 = pd.DataFrame({\"They buy\": buy_list})\n",
    "    df2 = pd.DataFrame({\"We recommend\" : rec_list})\n",
    "    df = pd.concat([df1, df2], axis=1, sort=False)\n",
    "    \n",
    "    print(index, \"번째 로그 데이터에 대한 결과\\n\")\n",
    "    display(df)\n",
    "    print(\"추천 적중 상품:\", tmp)\n",
    "    print(\"\\nAP:\", average_precision(match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_good_case(a, b, criteria=0.5):\n",
    "    good_map=[]\n",
    "    for index in range(len(a)):\n",
    "        buy_list = remove_dup(a[index])\n",
    "        rec_list = remove_dup(b[index])\n",
    "        match = np.zeros(len(b[index])).astype(np.int8).tolist()\n",
    "        for j in range(len(rec_list)):\n",
    "            if rec_list[j] in buy_list :\n",
    "                match[j] = 1\n",
    "        good_map.append(average_precision(match))\n",
    "    best_idx = []\n",
    "    for idx, v in enumerate(good_map):\n",
    "        if v >= criteria:\n",
    "            best_idx.append(idx)\n",
    "    return best_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_case_idx = find_good_case(a, b, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 번째 로그 데이터에 대한 결과\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>They buy</th>\n",
       "      <th>We recommend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Packaged Side Dishes</td>\n",
       "      <td>Travel Bags</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bakery</td>\n",
       "      <td>Fruit Vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hot Snacks</td>\n",
       "      <td>Fitness Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seasoned Meats</td>\n",
       "      <td>Leaf Vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chickens</td>\n",
       "      <td>Hand / Foot Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chilled Snacks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Travel Bags</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ham and Sausages</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Snacks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Curtains / Blinds</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decorative Accessories</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Fruit Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Leaf Vegetables</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mushrooms</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tofu / Bean Sprouts</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Yogurt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Processed Dairy Products</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dessert</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chilled Instant Foods</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Korean Traditional Snacks</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lighting Accessories</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     They buy      We recommend\n",
       "0        Packaged Side Dishes       Travel Bags\n",
       "1                      Bakery  Fruit Vegetables\n",
       "2                  Hot Snacks  Fitness Training\n",
       "3              Seasoned Meats   Leaf Vegetables\n",
       "4                    Chickens  Hand / Foot Care\n",
       "5              Chilled Snacks               NaN\n",
       "6                 Travel Bags               NaN\n",
       "7            Ham and Sausages               NaN\n",
       "8                      Snacks               NaN\n",
       "9           Curtains / Blinds               NaN\n",
       "10     Decorative Accessories               NaN\n",
       "11           Fruit Vegetables               NaN\n",
       "12            Leaf Vegetables               NaN\n",
       "13                  Mushrooms               NaN\n",
       "14        Tofu / Bean Sprouts               NaN\n",
       "15                     Yogurt               NaN\n",
       "16   Processed Dairy Products               NaN\n",
       "17                    Dessert               NaN\n",
       "18      Chilled Instant Foods               NaN\n",
       "19  Korean Traditional Snacks               NaN\n",
       "20       Lighting Accessories               NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추천 적중 상품: ['0번째: Travel Bags', '1번째: Fruit Vegetables', '3번째: Leaf Vegetables']\n",
      "\n",
      "AP: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "show_with_table(a,b, good_case_idx[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## Entropy Diversity \n",
    "- 추천 결과가 얼마나 분산 되어 있느냐를 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "ideal = 'abcde'\n",
    "probid = [ float(ideal.count(c)) / len(ideal) for c in dict.fromkeys(list(ideal))]\n",
    "entropy_ideal = - sum([ p * math.log(p) / math.log(2.0) for p in probid ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6094379124341005"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_ideal = - sum([ p * math.log(p) for p in probid])\n",
    "entropy_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_diversity(li):\n",
    "    total = []\n",
    "    for first_list in li:\n",
    "        for items in first_list:\n",
    "            total.append(items)\n",
    "    total_unique = list(set(total))\n",
    "    probid = [ float(total.count(c)) / len(total) for c in total_unique]\n",
    "    entropy_ideal = - sum([ p * math.log(p) for p in probid])\n",
    "    return entropy_ideal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6985442459601057"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_diversity(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
